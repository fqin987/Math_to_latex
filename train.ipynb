{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Python 3.6 \n",
    "Pytorch >= 0.4\n",
    "Written by Hongyu Wang in Beihang university\n",
    "'''\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy\n",
    "import torch.utils.data as data\n",
    "from data_iterator import dataIterator\n",
    "from Densenet_torchvision import densenet121\n",
    "from Attention_RNN import AttnDecoderRNN\n",
    "#from Resnet101 import resnet101\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "# if __name__ == '__main__':\n",
    "#     freeze_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the wer loss\n",
    "def cmp_result(label,rec):\n",
    "    dist_mat = numpy.zeros((len(label)+1, len(rec)+1),dtype='int32')\n",
    "    dist_mat[0,:] = range(len(rec) + 1)\n",
    "    dist_mat[:,0] = range(len(label) + 1)\n",
    "    for i in range(1, len(label) + 1):\n",
    "        for j in range(1, len(rec) + 1):\n",
    "            hit_score = dist_mat[i-1, j-1] + (label[i-1] != rec[j-1])\n",
    "            ins_score = dist_mat[i,j-1] + 1\n",
    "            del_score = dist_mat[i-1, j] + 1\n",
    "            dist_mat[i,j] = min(hit_score, ins_score, del_score)\n",
    "    dist = dist_mat[len(label), len(rec)]\n",
    "    return dist, len(label)\n",
    "\n",
    "def load_dict(dictFile):\n",
    "    fp=open(dictFile)\n",
    "    stuff=fp.readlines()\n",
    "    fp.close()\n",
    "    lexicon={}\n",
    "    for l in stuff:\n",
    "        w=l.strip().split()\n",
    "        lexicon[w[0]]=int(w[1])\n",
    "    print('total words/phones',len(lexicon))\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total words/phones 112\n",
      "total  8359 batch data loaded\n",
      "ignore 476 images\n",
      "total  925 batch data loaded\n",
      "ignore 61 images\n"
     ]
    }
   ],
   "source": [
    "datasets=['./offline-train.pkl','./train_caption.txt']\n",
    "valid_datasets=['./offline-test.pkl', './test_caption.txt']\n",
    "dictionaries=['./dictionary.txt']\n",
    "batch_Imagesize=500000\n",
    "valid_batch_Imagesize=500000\n",
    "# batch_size for training and testing\n",
    "batch_size=6\n",
    "batch_size_t=6\n",
    "# the max (label length/Image size) in training and testing\n",
    "# you can change 'maxlen','maxImagesize' by the size of your GPU\n",
    "maxlen=48\n",
    "maxImagesize= 100000\n",
    "# hidden_size in RNN\n",
    "hidden_size = 256\n",
    "# teacher_forcing_ratio \n",
    "teacher_forcing_ratio = 1\n",
    "# change the gpu id \n",
    "gpu = [0,1]\n",
    "# learning rate\n",
    "lr_rate = 0.0001\n",
    "# flag to remember when to change the learning rate\n",
    "flag = 0\n",
    "# exprate\n",
    "exprate = 0\n",
    "\n",
    "# worddicts\n",
    "worddicts = load_dict(dictionaries[0])\n",
    "worddicts_r = [None] * len(worddicts)\n",
    "for kk, vv in worddicts.items():\n",
    "        worddicts_r[vv] = kk\n",
    "\n",
    "#load train data and test data\n",
    "train,train_label = dataIterator(\n",
    "                                    datasets[0], datasets[1],worddicts,batch_size=1,\n",
    "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
    "                                 )\n",
    "len_train = len(train)\n",
    "\n",
    "test,test_label = dataIterator(\n",
    "                                    valid_datasets[0],valid_datasets[1],worddicts,batch_size=1,\n",
    "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
    "                                )\n",
    "len_test = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_dset(data.Dataset):\n",
    "    def __init__(self,train,train_label,batch_size):\n",
    "        self.train = train\n",
    "        self.train_label = train_label\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        train_setting = torch.from_numpy(numpy.array(self.train[index]))\n",
    "        label_setting = torch.from_numpy(numpy.array(self.train_label[index])).type(torch.LongTensor)\n",
    "\n",
    "        size = train_setting.size()\n",
    "        train_setting = train_setting.view(1,size[2],size[3])\n",
    "        label_setting = label_setting.view(-1)\n",
    "        return train_setting,label_setting\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train)\n",
    "\n",
    "\n",
    "off_image_train = custom_dset(train,train_label,batch_size)\n",
    "off_image_test = custom_dset(test,test_label,batch_size)\n",
    "\n",
    "# collate_fn is writting for padding imgs in batch. \n",
    "# As images in my dataset are different size, so the padding is necessary.\n",
    "# Padding images to the max image size in a mini-batch and cat a mask. \n",
    "def collate_fn(batch):\n",
    "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    img, label = zip(*batch)\n",
    "    aa1 = 0\n",
    "    bb1 = 0\n",
    "    k = 0\n",
    "    k1 = 0\n",
    "    max_len = len(label[0])+1\n",
    "    for j in range(len(img)):\n",
    "        size = img[j].size()\n",
    "        if size[1] > aa1:\n",
    "            aa1 = size[1]\n",
    "        if size[2] > bb1:\n",
    "            bb1 = size[2]\n",
    "\n",
    "    for ii in img:\n",
    "        ii = ii.float()\n",
    "        img_size_h = ii.size()[1]\n",
    "        img_size_w = ii.size()[2]\n",
    "        img_mask_sub_s = torch.ones(1,img_size_h,img_size_w).type(torch.FloatTensor)\n",
    "        img_mask_sub_s = img_mask_sub_s*255.0\n",
    "        img_mask_sub = torch.cat((ii,img_mask_sub_s),dim=0)\n",
    "        padding_h = aa1-img_size_h\n",
    "        padding_w = bb1-img_size_w\n",
    "        m = torch.nn.ZeroPad2d((0,padding_w,0,padding_h))\n",
    "        img_mask_sub_padding = m(img_mask_sub)\n",
    "        img_mask_sub_padding = img_mask_sub_padding.unsqueeze(0)\n",
    "        if k==0:\n",
    "            img_padding_mask = img_mask_sub_padding\n",
    "        else:\n",
    "            img_padding_mask = torch.cat((img_padding_mask,img_mask_sub_padding),dim=0)\n",
    "        k = k+1\n",
    "\n",
    "    for ii1 in label:\n",
    "        ii1 = ii1.long()\n",
    "        ii1 = ii1.unsqueeze(0)\n",
    "        ii1_len = ii1.size()[1]\n",
    "        m = torch.nn.ZeroPad2d((0,max_len-ii1_len,0,0))\n",
    "        ii1_padding = m(ii1)\n",
    "        if k1 == 0:\n",
    "            label_padding = ii1_padding\n",
    "        else:\n",
    "            label_padding = torch.cat((label_padding,ii1_padding),dim=0)\n",
    "        k1 = k1+1\n",
    "\n",
    "    img_padding_mask = img_padding_mask/255.0\n",
    "    return img_padding_mask, label_padding\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset = off_image_train,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    collate_fn = collate_fn,\n",
    "    # num_workers=2,\n",
    "    )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset = off_image_test,\n",
    "    batch_size = batch_size_t,\n",
    "    shuffle = True,\n",
    "    collate_fn = collate_fn,\n",
    "    # num_workers=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train(target_length,attn_decoder1,\n",
    "             output_highfeature, output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
    "             decoder_input,decoder_hidden,attention_sum,decoder_attention):\n",
    "    loss = 0\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    flag_z = [0]*batch_size\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        encoder_optimizer1.zero_grad()\n",
    "        decoder_optimizer1.zero_grad()\n",
    "        my_num = 0\n",
    "\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention, attention_sum = attn_decoder1(decoder_input,\n",
    "                                                                                             decoder_hidden,\n",
    "                                                                                             output_highfeature,\n",
    "                                                                                             output_area,\n",
    "                                                                                             attention_sum,\n",
    "                                                                                             decoder_attention,\n",
    "                                                                                             dense_input,batch_size,h_mask,w_mask,gpu)\n",
    "            \n",
    "            \n",
    "            #print(decoder_output.size()) (batch,1,112)\n",
    "            y = y.unsqueeze(0)\n",
    "            for i in range(batch_size):\n",
    "                if int(y[0][i][di]) == 0:\n",
    "                    flag_z[i] = flag_z[i]+1\n",
    "                    if flag_z[i] > 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        loss += criterion(decoder_output[i], y[:,i,di])\n",
    "                else:\n",
    "                    loss += criterion(decoder_output[i], y[:,i,di])\n",
    "\n",
    "            if int(y[0][0][di]) == 0:\n",
    "                break\n",
    "            decoder_input = y[:,:,di]\n",
    "            decoder_input = decoder_input.squeeze(0)\n",
    "            y = y.squeeze(0)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer1.step()\n",
    "        decoder_optimizer1.step()\n",
    "        return loss.item()\n",
    "\n",
    "    else:\n",
    "        encoder_optimizer1.zero_grad()\n",
    "        decoder_optimizer1.zero_grad()\n",
    "        my_num = 0\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention,attention_sum= attn_decoder1(decoder_input, decoder_hidden,\n",
    "                                                                                output_highfeature, output_area,\n",
    "                                                                                attention_sum,decoder_attention,dense_input,batch_size,\n",
    "                                                                                h_mask,w_mask,gpu)\n",
    "            #print(decoder_output.size()) 1*10*112\n",
    "            #print(y.size())  1*37\n",
    "            #topi (b,1)\n",
    "            topv,topi = torch.max(decoder_output,2)\n",
    "            decoder_input = topi\n",
    "            decoder_input = decoder_input.view(batch_size)\n",
    "\n",
    "            y = y.unsqueeze(0)\n",
    "            #print(y_t)\n",
    "\n",
    "            # 1*bs*17\n",
    "            for k in range(batch_size):\n",
    "                if int(y[0][k][di]) == 0:\n",
    "                    flag_z[k] = flag_z[k]+1\n",
    "                    if flag_z[k] > 1:\n",
    "                        continue\n",
    "                    else:\n",
    "                        loss += criterion(decoder_output[k], y[:,k,di])\n",
    "                else:\n",
    "                    loss += criterion(decoder_output[k], y[:,k,di])\n",
    "\n",
    "            y = y.squeeze(0)\n",
    "            # if int(topi[0]) == 0:\n",
    "            #     break\n",
    "        loss.backward()\n",
    "        encoder_optimizer1.step()\n",
    "        decoder_optimizer1.step()\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = [torch.cuda.current_device()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = densenet121()\n",
    "\n",
    "pthfile = r'densenet121-a639ec97.pth'\n",
    "pretrained_dict = torch.load(pthfile) \n",
    "encoder_dict = encoder.state_dict()\n",
    "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in encoder_dict}\n",
    "encoder_dict.update(pretrained_dict)\n",
    "encoder.load_state_dict(encoder_dict)\n",
    "\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size,112,dropout_p=0.5)\n",
    "\n",
    "encoder=encoder.cuda() #gpu\n",
    "attn_decoder1 = attn_decoder1.cuda()\n",
    "encoder = torch.nn.DataParallel(encoder, device_ids=gpu)\n",
    "attn_decoder1 = torch.nn.DataParallel(attn_decoder1, device_ids=gpu)\n",
    "# encoder = torch.nn.DataParallel(encoder)\n",
    "# attn_decoder1 = torch.nn.DataParallel(attn_decoder1)\n",
    "\n",
    "\n",
    "def imresize(im,sz):\n",
    "    pil_im = Image.fromarray(im)\n",
    "    return numpy.array(pil_im.resize(sz))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 1.436%, running_loss is 53.282975\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 2.871%, running_loss is 53.142089\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 4.307%, running_loss is 51.411293\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 5.742%, running_loss is 54.451891\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 7.178%, running_loss is 53.865111\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 8.613%, running_loss is 52.684832\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 10.049%, running_loss is 46.951953\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 11.485%, running_loss is 48.256820\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 12.920%, running_loss is 53.979900\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 14.356%, running_loss is 52.238405\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 15.791%, running_loss is 49.908275\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 17.227%, running_loss is 46.822000\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 18.663%, running_loss is 54.187911\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 20.098%, running_loss is 48.131157\n",
      "epoch is 0, lr rate is 0.00010, te is 1.000, batch_size is 6, loading for 21.534%, running_loss is 44.908811\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "# encoder.load_state_dict(torch.load('model/encoder_lr0.00001_BN_te1_d05_SGD_bs8_mask_conv_bn_b.pkl'))\n",
    "# attn_decoder1.load_state_dict(torch.load('model/attn_decoder_lr0.00001_BN_te1_d05_SGD_bs8_mask_conv_bn_b.pkl'))\n",
    "\n",
    "decoder_input_init = torch.LongTensor([111]*batch_size).cuda() #gpu\n",
    "decoder_hidden_init = torch.randn(batch_size, 1, hidden_size).cuda()\n",
    "# decoder_input_init = torch.LongTensor([111]*batch_size)\n",
    "# decoder_hidden_init = torch.randn(batch_size, 1, hidden_size)\n",
    "nn.init.xavier_uniform_(decoder_hidden_init)\n",
    "\n",
    "encoder_optimizer1 = torch.optim.Adam(encoder.parameters(), lr=lr_rate)\n",
    "decoder_optimizer1 = torch.optim.Adam(attn_decoder1.parameters(), lr=lr_rate)\n",
    "\n",
    "for epoch in tqdm(range(5)):\n",
    "#     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
    "#     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
    "\n",
    "    # # if using SGD optimizer\n",
    "    # if epoch+1 == 50:\n",
    "    #     lr_rate = lr_rate/10\n",
    "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
    "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
    "    # if epoch+1 == 75:\n",
    "    #     lr_rate = lr_rate/10\n",
    "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
    "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
    "\n",
    "\n",
    "    running_loss=0\n",
    "    whole_loss = 0\n",
    "\n",
    "    encoder.train(mode=True)\n",
    "    attn_decoder1.train(mode=True)\n",
    "\n",
    "    # this is the train\n",
    "#     for step,(x,y) in tqdm(enumerate(train_loader)):\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        if x.size()[0]<batch_size:\n",
    "            break\n",
    "        h_mask = []\n",
    "        w_mask = []\n",
    "        for i in x:\n",
    "            #h*w\n",
    "            size_mask = i[1].size()\n",
    "            s_w = str(i[1][0])\n",
    "            s_h = str(i[1][:,1])\n",
    "            w = s_w.count('1')\n",
    "            h = s_h.count('1')\n",
    "            h_comp = int(h/16)+1\n",
    "            w_comp = int(w/16)+1\n",
    "            h_mask.append(h_comp)\n",
    "            w_mask.append(w_comp)\n",
    "\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        # out is CNN featuremaps\n",
    "        output_highfeature = encoder(x)\n",
    "        x_mean=[]\n",
    "        for i in output_highfeature:\n",
    "            x_mean.append(float(torch.mean(i)))\n",
    "        # x_mean = torch.mean(output_highfeature)\n",
    "        # x_mean = float(x_mean)\n",
    "        for i in range(batch_size):\n",
    "            decoder_hidden_init[i] = decoder_hidden_init[i]*x_mean[i]\n",
    "            decoder_hidden_init[i] = torch.tanh(decoder_hidden_init[i])\n",
    "\n",
    "        # dense_input is height and output_area is width which is bb\n",
    "        output_area1 = output_highfeature.size()\n",
    "\n",
    "        output_area = output_area1[3]\n",
    "        dense_input = output_area1[2]\n",
    "        target_length = y.size()[1]\n",
    "        attention_sum_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
    "        decoder_attention_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
    "\n",
    "        running_loss += my_train(target_length,attn_decoder1,output_highfeature,\n",
    "                                output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
    "                                decoder_input_init,decoder_hidden_init,attention_sum_init,decoder_attention_init)\n",
    "\n",
    "        \n",
    "        if step % 20 == 19:\n",
    "            pre = ((step+1)/len_train)*100*batch_size\n",
    "            whole_loss += running_loss\n",
    "            running_loss = running_loss/(batch_size*20)\n",
    "            print('epoch is %d, lr rate is %.5f, te is %.3f, batch_size is %d, loading for %.3f%%, running_loss is %f' %(epoch,lr_rate,teacher_forcing_ratio, batch_size,pre,running_loss))\n",
    "            # with open(\"training_data/running_loss_%.5f_pre_GN_te05_d02_all.txt\" %(lr_rate),\"a\") as f:\n",
    "            #     f.write(\"%s\\n\"%(str(running_loss)))\n",
    "            running_loss = 0\n",
    "\n",
    "    loss_all_out = whole_loss / len_train\n",
    "    print(\"epoch is %d, the whole loss is %f\" % (epoch, loss_all_out))\n",
    "    # with open(\"training_data/whole_loss_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
    "    #     f.write(\"%s\\n\" % (str(loss_all_out)))\n",
    "\n",
    "    # this is the prediction and compute wer loss\n",
    "    total_dist = 0\n",
    "    total_label = 0\n",
    "    total_line = 0\n",
    "    total_line_rec = 0\n",
    "    whole_loss_t = 0\n",
    "\n",
    "    encoder.eval()\n",
    "    attn_decoder1.eval()\n",
    "    print('Now, begin testing!!')\n",
    "\n",
    "#     for step_t, (x_t, y_t) in tqdm(enumerate(test_loader)):\n",
    "    for step_t, (x_t, y_t) in enumerate(test_loader):\n",
    "        x_real_high = x_t.size()[2]\n",
    "        x_real_width = x_t.size()[3]\n",
    "        if x_t.size()[0]<batch_size_t:\n",
    "            break\n",
    "        print('testing for %.3f%%'%(step_t*100*batch_size_t/len_test),end='\\r')\n",
    "        h_mask_t = []\n",
    "        w_mask_t = []\n",
    "        for i in x_t:\n",
    "            #h*w\n",
    "            size_mask_t = i[1].size()\n",
    "            s_w_t = str(i[1][0])\n",
    "            s_h_t = str(i[1][:,1])\n",
    "            w_t = s_w_t.count('1')\n",
    "            h_t = s_h_t.count('1')\n",
    "            h_comp_t = int(h_t/16)+1\n",
    "            w_comp_t = int(w_t/16)+1\n",
    "            h_mask_t.append(h_comp_t)\n",
    "            w_mask_t.append(w_comp_t)\n",
    "\n",
    "        x_t = x_t.cuda()\n",
    "        y_t = y_t.cuda()\n",
    "        output_highfeature_t = encoder(x_t)\n",
    "\n",
    "        x_mean_t = torch.mean(output_highfeature_t)\n",
    "        x_mean_t = float(x_mean_t)\n",
    "        output_area_t1 = output_highfeature_t.size()\n",
    "        output_area_t = output_area_t1[3]\n",
    "        dense_input = output_area_t1[2]\n",
    "\n",
    "        decoder_input_t = torch.LongTensor([111]*batch_size_t)\n",
    "        decoder_input_t = decoder_input_t.cuda()\n",
    "        decoder_hidden_t = torch.randn(batch_size_t, 1, hidden_size).cuda()\n",
    "        nn.init.xavier_uniform_(decoder_hidden_t)\n",
    "\n",
    "        x_mean_t=[]\n",
    "        for i in output_highfeature_t:\n",
    "            x_mean_t.append(float(torch.mean(i)))\n",
    "        # x_mean = torch.mean(output_highfeature)\n",
    "        # x_mean = float(x_mean)\n",
    "        for i in range(batch_size_t):\n",
    "            decoder_hidden_t[i] = decoder_hidden_t[i]*x_mean_t[i]\n",
    "            decoder_hidden_t[i] = torch.tanh(decoder_hidden_t[i])\n",
    "\n",
    "        prediction = torch.zeros(batch_size_t,maxlen)\n",
    "        #label = torch.zeros(batch_size_t,maxlen)\n",
    "        prediction_sub = []\n",
    "        label_sub = []\n",
    "        decoder_attention_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
    "        attention_sum_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
    "        flag_z_t = [0]*batch_size_t\n",
    "        loss_t = 0\n",
    "        m = torch.nn.ZeroPad2d((0,maxlen-y_t.size()[1],0,0))\n",
    "        y_t = m(y_t)\n",
    "        for i in range(maxlen):\n",
    "            decoder_output, decoder_hidden_t, decoder_attention_t, attention_sum_t = attn_decoder1(decoder_input_t,\n",
    "                                                                                             decoder_hidden_t,\n",
    "                                                                                             output_highfeature_t,\n",
    "                                                                                             output_area_t,\n",
    "                                                                                             attention_sum_t,\n",
    "                                                                                             decoder_attention_t,dense_input,batch_size_t,h_mask_t,w_mask_t,gpu)\n",
    "\n",
    "            ### you can see the attention when testing\n",
    "\n",
    "            # print('this is',i)\n",
    "            # for i in range(batch_size_t):\n",
    "            #     x_real = numpy.array(x_t[i][0].data.cpu())\n",
    "\n",
    "            #     show = numpy.array(decoder_attention_t[i][0].data.cpu())\n",
    "            #     show = imresize(show,(x_real_width,x_real_high))\n",
    "            #     k_max = show.max()\n",
    "            #     show = show/k_max\n",
    "\n",
    "            #     show_x = x_real+show\n",
    "            #     plt.imshow(show_x, interpolation='nearest', cmap='gray_r')\n",
    "            #     plt.show()\n",
    "            \n",
    "            topv,topi = torch.max(decoder_output,2)\n",
    "            # if torch.sum(y_t[0,:,i])==0:\n",
    "            #     y_t = y_t.squeeze(0)\n",
    "            #     break\n",
    "            if torch.sum(topi)==0:\n",
    "                break\n",
    "            decoder_input_t = topi\n",
    "            decoder_input_t = decoder_input_t.view(batch_size_t)\n",
    "\n",
    "            # prediction\n",
    "            prediction[:,i] = decoder_input_t\n",
    "\n",
    "        for i in range(batch_size_t):\n",
    "            for j in range(maxlen):\n",
    "                if int(prediction[i][j]) ==0:\n",
    "                    break\n",
    "                else:\n",
    "                    prediction_sub.append(int(prediction[i][j]))\n",
    "            if len(prediction_sub)<maxlen:\n",
    "                prediction_sub.append(0)\n",
    "\n",
    "            for k in range(y_t.size()[1]):\n",
    "                if int(y_t[i][k]) ==0:\n",
    "                    break\n",
    "                else:\n",
    "                    label_sub.append(int(y_t[i][k]))\n",
    "            label_sub.append(0)\n",
    "\n",
    "            dist, llen = cmp_result(label_sub, prediction_sub)\n",
    "            total_dist += dist\n",
    "            total_label += llen\n",
    "            total_line += 1\n",
    "            if dist == 0:\n",
    "                total_line_rec = total_line_rec+ 1\n",
    "\n",
    "            label_sub = []\n",
    "            prediction_sub = []\n",
    "\n",
    "    print('total_line_rec is',total_line_rec)\n",
    "    wer = float(total_dist) / total_label\n",
    "    sacc = float(total_line_rec) / total_line\n",
    "    print('wer is %.5f' % (wer))\n",
    "    print('sacc is %.5f ' % (sacc))\n",
    "    # print('whole loss is %.5f'%(whole_loss_t/925))\n",
    "    # with open(\"training_data/wer_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
    "    #     f.write(\"%s\\n\" % (str(wer)))\n",
    "\n",
    "    if (sacc > exprate):\n",
    "        exprate = sacc\n",
    "        print(exprate)\n",
    "        print(\"saving the model....\")\n",
    "        print('encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl' %(lr_rate))\n",
    "        torch.save(encoder.state_dict(), 'model/encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl'%(lr_rate))\n",
    "        torch.save(attn_decoder1.state_dict(), 'model/attn_decoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl'%(lr_rate))\n",
    "        print(\"done\")\n",
    "        flag = 0\n",
    "    else:\n",
    "        flag = flag+1\n",
    "        print('the best is %f' % (exprate))\n",
    "        print('the loss is bigger than before,so do not save the model')\n",
    "\n",
    "    if flag == 10:\n",
    "        lr_rate = lr_rate*0.1\n",
    "        flag = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
