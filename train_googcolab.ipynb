{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKlVVHh19aK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccc9251b-4b01-4e79-fea5-ce1b92a9e626"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhu_7Apj3OtE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0dfdc171-8302-4b6f-8647-440124c851ed"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Math_to_latex')\n",
        "print(sys.path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/My Drive/Math_to_latex']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDi7vhcu1z1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Python 3.6 \n",
        "Pytorch >= 0.4\n",
        "Written by Hongyu Wang in Beihang university\n",
        "'''\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy\n",
        "import torch.utils.data as data\n",
        "from data_iterator import dataIterator\n",
        "from Densenet_torchvision import densenet121\n",
        "from Attention_RNN import AttnDecoderRNN\n",
        "#from Resnet101 import resnet101\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "# if __name__ == '__main__':\n",
        "#     freeze_support()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZlFifO13icM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d5b5b15-9381-4198-9a86-5d394d075f4d"
      },
      "source": [
        "gpu = torch.cuda.current_device()\n",
        "print(gpu)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsClwMF51z1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compute the wer loss\n",
        "def cmp_result(label,rec):\n",
        "    dist_mat = numpy.zeros((len(label)+1, len(rec)+1),dtype='int32')\n",
        "    dist_mat[0,:] = range(len(rec) + 1)\n",
        "    dist_mat[:,0] = range(len(label) + 1)\n",
        "    for i in range(1, len(label) + 1):\n",
        "        for j in range(1, len(rec) + 1):\n",
        "            hit_score = dist_mat[i-1, j-1] + (label[i-1] != rec[j-1])\n",
        "            ins_score = dist_mat[i,j-1] + 1\n",
        "            del_score = dist_mat[i-1, j] + 1\n",
        "            dist_mat[i,j] = min(hit_score, ins_score, del_score)\n",
        "    dist = dist_mat[len(label), len(rec)]\n",
        "    return dist, len(label)\n",
        "\n",
        "def load_dict(dictFile):\n",
        "    fp=open(dictFile)\n",
        "    stuff=fp.readlines()\n",
        "    fp.close()\n",
        "    lexicon={}\n",
        "    for l in stuff:\n",
        "        w=l.strip().split()\n",
        "        lexicon[w[0]]=int(w[1])\n",
        "    print('total words/phones',len(lexicon))\n",
        "    return lexicon"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezuzFh91z19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9cd8afe7-f634-4e8b-9418-a9870fba7d87"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Math_to_latex/'\n",
        "datasets=[f'{PATH}offline-train.pkl',f'{PATH}/train_caption.txt']\n",
        "valid_datasets=[f'{PATH}offline-test.pkl', f'{PATH}test_caption.txt']\n",
        "dictionaries=[f'{PATH}dictionary.txt']\n",
        "batch_Imagesize=500000\n",
        "valid_batch_Imagesize=500000\n",
        "# batch_size for training and testing\n",
        "batch_size=6\n",
        "batch_size_t=6\n",
        "# the max (label length/Image size) in training and testing\n",
        "# you can change 'maxlen','maxImagesize' by the size of your GPU\n",
        "maxlen=48\n",
        "maxImagesize= 100000\n",
        "# hidden_size in RNN\n",
        "hidden_size = 256\n",
        "# teacher_forcing_ratio \n",
        "teacher_forcing_ratio = 1\n",
        "# change the gpu id \n",
        "gpu = [0,1]\n",
        "# learning rate\n",
        "# lr_rate = 0.0001\n",
        "lr_rate = 0.005\n",
        "# flag to remember when to change the learning rate\n",
        "flag = 0\n",
        "# exprate\n",
        "exprate = 0\n",
        "\n",
        "# worddicts\n",
        "worddicts = load_dict(dictionaries[0])\n",
        "worddicts_r = [None] * len(worddicts)\n",
        "for kk, vv in worddicts.items():\n",
        "        worddicts_r[vv] = kk\n",
        "\n",
        "#load train data and test data\n",
        "train,train_label = dataIterator(\n",
        "                                    datasets[0], datasets[1],worddicts,batch_size=1,\n",
        "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
        "                                 )\n",
        "len_train = len(train)\n",
        "\n",
        "test,test_label = dataIterator(\n",
        "                                    valid_datasets[0],valid_datasets[1],worddicts,batch_size=1,\n",
        "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
        "                                )\n",
        "len_test = len(test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total words/phones 112\n",
            "total  8359 batch data loaded\n",
            "ignore 476 images\n",
            "total  925 batch data loaded\n",
            "ignore 61 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D97Gj3QK1z2F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class custom_dset(data.Dataset):\n",
        "    def __init__(self,train,train_label,batch_size):\n",
        "        self.train = train\n",
        "        self.train_label = train_label\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        train_setting = torch.from_numpy(numpy.array(self.train[index]))\n",
        "        label_setting = torch.from_numpy(numpy.array(self.train_label[index])).type(torch.LongTensor)\n",
        "\n",
        "        size = train_setting.size()\n",
        "        train_setting = train_setting.view(1,size[2],size[3])\n",
        "        label_setting = label_setting.view(-1)\n",
        "        return train_setting,label_setting\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train)\n",
        "\n",
        "\n",
        "off_image_train = custom_dset(train,train_label,batch_size)\n",
        "off_image_test = custom_dset(test,test_label,batch_size)\n",
        "\n",
        "# collate_fn is writting for padding imgs in batch. \n",
        "# As images in my dataset are different size, so the padding is necessary.\n",
        "# Padding images to the max image size in a mini-batch and cat a mask. \n",
        "def collate_fn(batch):\n",
        "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
        "    img, label = zip(*batch)\n",
        "    aa1 = 0\n",
        "    bb1 = 0\n",
        "    k = 0\n",
        "    k1 = 0\n",
        "    max_len = len(label[0])+1\n",
        "    for j in range(len(img)):\n",
        "        size = img[j].size()\n",
        "        if size[1] > aa1:\n",
        "            aa1 = size[1]\n",
        "        if size[2] > bb1:\n",
        "            bb1 = size[2]\n",
        "\n",
        "    for ii in img:\n",
        "        ii = ii.float()\n",
        "        img_size_h = ii.size()[1]\n",
        "        img_size_w = ii.size()[2]\n",
        "        img_mask_sub_s = torch.ones(1,img_size_h,img_size_w).type(torch.FloatTensor)\n",
        "        img_mask_sub_s = img_mask_sub_s*255.0\n",
        "        img_mask_sub = torch.cat((ii,img_mask_sub_s),dim=0)\n",
        "        padding_h = aa1-img_size_h\n",
        "        padding_w = bb1-img_size_w\n",
        "        m = torch.nn.ZeroPad2d((0,padding_w,0,padding_h))\n",
        "        img_mask_sub_padding = m(img_mask_sub)\n",
        "        img_mask_sub_padding = img_mask_sub_padding.unsqueeze(0)\n",
        "        if k==0:\n",
        "            img_padding_mask = img_mask_sub_padding\n",
        "        else:\n",
        "            img_padding_mask = torch.cat((img_padding_mask,img_mask_sub_padding),dim=0)\n",
        "        k = k+1\n",
        "\n",
        "    for ii1 in label:\n",
        "        ii1 = ii1.long()\n",
        "        ii1 = ii1.unsqueeze(0)\n",
        "        ii1_len = ii1.size()[1]\n",
        "        m = torch.nn.ZeroPad2d((0,max_len-ii1_len,0,0))\n",
        "        ii1_padding = m(ii1)\n",
        "        if k1 == 0:\n",
        "            label_padding = ii1_padding\n",
        "        else:\n",
        "            label_padding = torch.cat((label_padding,ii1_padding),dim=0)\n",
        "        k1 = k1+1\n",
        "\n",
        "    img_padding_mask = img_padding_mask/255.0\n",
        "    return img_padding_mask, label_padding\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = off_image_train,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    # num_workers=2,\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = off_image_test,\n",
        "    batch_size = batch_size_t,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    # num_workers=2,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41v3UxF71z2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_train(target_length,attn_decoder1,\n",
        "             output_highfeature, output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
        "             decoder_input,decoder_hidden,attention_sum,decoder_attention):\n",
        "    loss = 0\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    flag_z = [0]*batch_size\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        encoder_optimizer1.zero_grad()\n",
        "        decoder_optimizer1.zero_grad()\n",
        "        my_num = 0\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention, attention_sum = attn_decoder1(decoder_input,\n",
        "                                                                                             decoder_hidden,\n",
        "                                                                                             output_highfeature,\n",
        "                                                                                             output_area,\n",
        "                                                                                             attention_sum,\n",
        "                                                                                             decoder_attention,\n",
        "                                                                                             dense_input,batch_size,h_mask,w_mask,gpu)\n",
        "            \n",
        "            \n",
        "            #print(decoder_output.size()) (batch,1,112)\n",
        "            y = y.unsqueeze(0)\n",
        "            for i in range(batch_size):\n",
        "                if int(y[0][i][di]) == 0:\n",
        "                    flag_z[i] = flag_z[i]+1\n",
        "                    if flag_z[i] > 1:\n",
        "                        continue\n",
        "                    else:\n",
        "                        loss += criterion(decoder_output[i], y[:,i,di])\n",
        "                else:\n",
        "                    loss += criterion(decoder_output[i], y[:,i,di])\n",
        "\n",
        "            if int(y[0][0][di]) == 0:\n",
        "                break\n",
        "            decoder_input = y[:,:,di]\n",
        "            decoder_input = decoder_input.squeeze(0)\n",
        "            y = y.squeeze(0)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer1.step()\n",
        "        decoder_optimizer1.step()\n",
        "        return loss.item()\n",
        "\n",
        "    else:\n",
        "        encoder_optimizer1.zero_grad()\n",
        "        decoder_optimizer1.zero_grad()\n",
        "        my_num = 0\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention,attention_sum= attn_decoder1(decoder_input, decoder_hidden,\n",
        "                                                                                output_highfeature, output_area,\n",
        "                                                                                attention_sum,decoder_attention,dense_input,batch_size,\n",
        "                                                                                h_mask,w_mask,gpu)\n",
        "            #print(decoder_output.size()) 1*10*112\n",
        "            #print(y.size())  1*37\n",
        "            #topi (b,1)\n",
        "            topv,topi = torch.max(decoder_output,2)\n",
        "            decoder_input = topi\n",
        "            decoder_input = decoder_input.view(batch_size)\n",
        "\n",
        "            y = y.unsqueeze(0)\n",
        "            #print(y_t)\n",
        "\n",
        "            # 1*bs*17\n",
        "            for k in range(batch_size):\n",
        "                if int(y[0][k][di]) == 0:\n",
        "                    flag_z[k] = flag_z[k]+1\n",
        "                    if flag_z[k] > 1:\n",
        "                        continue\n",
        "                    else:\n",
        "                        loss += criterion(decoder_output[k], y[:,k,di])\n",
        "                else:\n",
        "                    loss += criterion(decoder_output[k], y[:,k,di])\n",
        "\n",
        "            y = y.squeeze(0)\n",
        "            # if int(topi[0]) == 0:\n",
        "            #     break\n",
        "        loss.backward()\n",
        "        encoder_optimizer1.step()\n",
        "        decoder_optimizer1.step()\n",
        "        return loss.item()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2k8uTbz313W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu = [torch.cuda.current_device()]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVuKzMZe1z2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = densenet121()\n",
        "\n",
        "pthfile = f'{PATH}densenet121-a639ec97.pth'\n",
        "pretrained_dict = torch.load(pthfile) \n",
        "encoder_dict = encoder.state_dict()\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in encoder_dict}\n",
        "encoder_dict.update(pretrained_dict)\n",
        "encoder.load_state_dict(encoder_dict)\n",
        "\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size,112,dropout_p=0.5)\n",
        "\n",
        "encoder=encoder.cuda() #gpu\n",
        "attn_decoder1 = attn_decoder1.cuda()\n",
        "encoder = torch.nn.DataParallel(encoder, device_ids=gpu)\n",
        "attn_decoder1 = torch.nn.DataParallel(attn_decoder1, device_ids=gpu)\n",
        "# encoder = torch.nn.DataParallel(encoder)\n",
        "# attn_decoder1 = torch.nn.DataParallel(attn_decoder1)\n",
        "\n",
        "\n",
        "def imresize(im,sz):\n",
        "    pil_im = Image.fromarray(im)\n",
        "    return numpy.array(pil_im.resize(sz))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ4hWX0x1z2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "61333323-d681-4d8e-97a0-5f8e362f1cc1"
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "# encoder.load_state_dict(torch.load('model/encoder_lr0.00001_BN_te1_d05_SGD_bs8_mask_conv_bn_b.pkl'))\n",
        "# attn_decoder1.load_state_dict(torch.load('model/attn_decoder_lr0.00001_BN_te1_d05_SGD_bs8_mask_conv_bn_b.pkl'))\n",
        "\n",
        "decoder_input_init = torch.LongTensor([111]*batch_size).cuda() #gpu\n",
        "decoder_hidden_init = torch.randn(batch_size, 1, hidden_size).cuda()\n",
        "# decoder_input_init = torch.LongTensor([111]*batch_size)\n",
        "# decoder_hidden_init = torch.randn(batch_size, 1, hidden_size)\n",
        "nn.init.xavier_uniform_(decoder_hidden_init)\n",
        "\n",
        "\n",
        "encoder_optimizer1 = torch.optim.Adam(encoder.parameters(), lr=lr_rate)\n",
        "decoder_optimizer1 = torch.optim.Adam(attn_decoder1.parameters(), lr=lr_rate)\n",
        "\n",
        "for epoch in tqdm(range(5)):\n",
        "#     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "#     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "\n",
        "    # # if using SGD optimizer\n",
        "    # if epoch+1 == 50:\n",
        "    #     lr_rate = lr_rate/10\n",
        "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    # if epoch+1 == 75:\n",
        "    #     lr_rate = lr_rate/10\n",
        "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    whole_loss = 0\n",
        "\n",
        "    encoder.train(mode=True)\n",
        "    attn_decoder1.train(mode=True)\n",
        "\n",
        "    # this is the train\n",
        "#     for step,(x,y) in tqdm(enumerate(train_loader)):\n",
        "    for step,(x,y) in enumerate(train_loader):\n",
        "        if x.size()[0]<batch_size:\n",
        "            break\n",
        "        h_mask = []\n",
        "        w_mask = []\n",
        "        for i in x:\n",
        "            #h*w\n",
        "            size_mask = i[1].size()\n",
        "            s_w = str(i[1][0])\n",
        "            s_h = str(i[1][:,1])\n",
        "            w = s_w.count('1')\n",
        "            h = s_h.count('1')\n",
        "            h_comp = int(h/16)+1\n",
        "            w_comp = int(w/16)+1\n",
        "            h_mask.append(h_comp)\n",
        "            w_mask.append(w_comp)\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        # out is CNN featuremaps\n",
        "        output_highfeature = encoder(x)\n",
        "        x_mean=[]\n",
        "        for i in output_highfeature:\n",
        "            x_mean.append(float(torch.mean(i)))\n",
        "        # x_mean = torch.mean(output_highfeature)\n",
        "        # x_mean = float(x_mean)\n",
        "        for i in range(batch_size):\n",
        "            decoder_hidden_init[i] = decoder_hidden_init[i]*x_mean[i]\n",
        "            decoder_hidden_init[i] = torch.tanh(decoder_hidden_init[i])\n",
        "\n",
        "        # dense_input is height and output_area is width which is bb\n",
        "        output_area1 = output_highfeature.size()\n",
        "\n",
        "        output_area = output_area1[3]\n",
        "        dense_input = output_area1[2]\n",
        "        target_length = y.size()[1]\n",
        "        attention_sum_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
        "        decoder_attention_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
        "\n",
        "        running_loss += my_train(target_length,attn_decoder1,output_highfeature,\n",
        "                                output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
        "                                decoder_input_init,decoder_hidden_init,attention_sum_init,decoder_attention_init)\n",
        "\n",
        "        \n",
        "        if step % 20 == 19:\n",
        "            pre = ((step+1)/len_train)*100*batch_size\n",
        "            whole_loss += running_loss\n",
        "            running_loss = running_loss/(batch_size*20)\n",
        "            print('epoch is %d, lr rate is %.5f, te is %.3f, batch_size is %d, loading for %.3f%%, running_loss is %f' %(epoch,lr_rate,teacher_forcing_ratio, batch_size,pre,running_loss))\n",
        "            # with open(\"training_data/running_loss_%.5f_pre_GN_te05_d02_all.txt\" %(lr_rate),\"a\") as f:\n",
        "            #     f.write(\"%s\\n\"%(str(running_loss)))\n",
        "            running_loss = 0\n",
        "\n",
        "    loss_all_out = whole_loss / len_train\n",
        "    print(\"epoch is %d, the whole loss is %f\" % (epoch, loss_all_out))\n",
        "    # with open(\"training_data/whole_loss_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "    #     f.write(\"%s\\n\" % (str(loss_all_out)))\n",
        "\n",
        "    # this is the prediction and compute wer loss\n",
        "    total_dist = 0\n",
        "    total_label = 0\n",
        "    total_line = 0\n",
        "    total_line_rec = 0\n",
        "    whole_loss_t = 0\n",
        "\n",
        "    encoder.eval()\n",
        "    attn_decoder1.eval()\n",
        "    print('Now, begin testing!!')\n",
        "\n",
        "#     for step_t, (x_t, y_t) in tqdm(enumerate(test_loader)):\n",
        "    for step_t, (x_t, y_t) in enumerate(test_loader):\n",
        "        x_real_high = x_t.size()[2]\n",
        "        x_real_width = x_t.size()[3]\n",
        "        if x_t.size()[0]<batch_size_t:\n",
        "            break\n",
        "        print('testing for %.3f%%'%(step_t*100*batch_size_t/len_test),end='\\r')\n",
        "        h_mask_t = []\n",
        "        w_mask_t = []\n",
        "        for i in x_t:\n",
        "            #h*w\n",
        "            size_mask_t = i[1].size()\n",
        "            s_w_t = str(i[1][0])\n",
        "            s_h_t = str(i[1][:,1])\n",
        "            w_t = s_w_t.count('1')\n",
        "            h_t = s_h_t.count('1')\n",
        "            h_comp_t = int(h_t/16)+1\n",
        "            w_comp_t = int(w_t/16)+1\n",
        "            h_mask_t.append(h_comp_t)\n",
        "            w_mask_t.append(w_comp_t)\n",
        "\n",
        "        x_t = x_t.cuda()\n",
        "        y_t = y_t.cuda()\n",
        "        output_highfeature_t = encoder(x_t)\n",
        "\n",
        "        x_mean_t = torch.mean(output_highfeature_t)\n",
        "        x_mean_t = float(x_mean_t)\n",
        "        output_area_t1 = output_highfeature_t.size()\n",
        "        output_area_t = output_area_t1[3]\n",
        "        dense_input = output_area_t1[2]\n",
        "\n",
        "        decoder_input_t = torch.LongTensor([111]*batch_size_t)\n",
        "        decoder_input_t = decoder_input_t.cuda()\n",
        "        decoder_hidden_t = torch.randn(batch_size_t, 1, hidden_size).cuda()\n",
        "        nn.init.xavier_uniform_(decoder_hidden_t)\n",
        "\n",
        "        x_mean_t=[]\n",
        "        for i in output_highfeature_t:\n",
        "            x_mean_t.append(float(torch.mean(i)))\n",
        "        # x_mean = torch.mean(output_highfeature)\n",
        "        # x_mean = float(x_mean)\n",
        "        for i in range(batch_size_t):\n",
        "            decoder_hidden_t[i] = decoder_hidden_t[i]*x_mean_t[i]\n",
        "            decoder_hidden_t[i] = torch.tanh(decoder_hidden_t[i])\n",
        "\n",
        "        prediction = torch.zeros(batch_size_t,maxlen)\n",
        "        #label = torch.zeros(batch_size_t,maxlen)\n",
        "        prediction_sub = []\n",
        "        label_sub = []\n",
        "        decoder_attention_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "        attention_sum_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "        flag_z_t = [0]*batch_size_t\n",
        "        loss_t = 0\n",
        "        m = torch.nn.ZeroPad2d((0,maxlen-y_t.size()[1],0,0))\n",
        "        y_t = m(y_t)\n",
        "        for i in range(maxlen):\n",
        "            decoder_output, decoder_hidden_t, decoder_attention_t, attention_sum_t = attn_decoder1(decoder_input_t,\n",
        "                                                                                             decoder_hidden_t,\n",
        "                                                                                             output_highfeature_t,\n",
        "                                                                                             output_area_t,\n",
        "                                                                                             attention_sum_t,\n",
        "                                                                                             decoder_attention_t,dense_input,batch_size_t,h_mask_t,w_mask_t,gpu)\n",
        "\n",
        "            ### you can see the attention when testing\n",
        "\n",
        "            # print('this is',i)\n",
        "            # for i in range(batch_size_t):\n",
        "            #     x_real = numpy.array(x_t[i][0].data.cpu())\n",
        "\n",
        "            #     show = numpy.array(decoder_attention_t[i][0].data.cpu())\n",
        "            #     show = imresize(show,(x_real_width,x_real_high))\n",
        "            #     k_max = show.max()\n",
        "            #     show = show/k_max\n",
        "\n",
        "            #     show_x = x_real+show\n",
        "            #     plt.imshow(show_x, interpolation='nearest', cmap='gray_r')\n",
        "            #     plt.show()\n",
        "            \n",
        "            topv,topi = torch.max(decoder_output,2)\n",
        "            # if torch.sum(y_t[0,:,i])==0:\n",
        "            #     y_t = y_t.squeeze(0)\n",
        "            #     break\n",
        "            if torch.sum(topi)==0:\n",
        "                break\n",
        "            decoder_input_t = topi\n",
        "            decoder_input_t = decoder_input_t.view(batch_size_t)\n",
        "\n",
        "            # prediction\n",
        "            prediction[:,i] = decoder_input_t\n",
        "\n",
        "        for i in range(batch_size_t):\n",
        "            for j in range(maxlen):\n",
        "                if int(prediction[i][j]) ==0:\n",
        "                    break\n",
        "                else:\n",
        "                    prediction_sub.append(int(prediction[i][j]))\n",
        "            if len(prediction_sub)<maxlen:\n",
        "                prediction_sub.append(0)\n",
        "\n",
        "            for k in range(y_t.size()[1]):\n",
        "                if int(y_t[i][k]) ==0:\n",
        "                    break\n",
        "                else:\n",
        "                    label_sub.append(int(y_t[i][k]))\n",
        "            label_sub.append(0)\n",
        "\n",
        "            dist, llen = cmp_result(label_sub, prediction_sub)\n",
        "            total_dist += dist\n",
        "            total_label += llen\n",
        "            total_line += 1\n",
        "            if dist == 0:\n",
        "                total_line_rec = total_line_rec+ 1\n",
        "\n",
        "            label_sub = []\n",
        "            prediction_sub = []\n",
        "\n",
        "    print('total_line_rec is',total_line_rec)\n",
        "    wer = float(total_dist) / total_label\n",
        "    sacc = float(total_line_rec) / total_line\n",
        "    print('wer is %.5f' % (wer))\n",
        "    print('sacc is %.5f ' % (sacc))\n",
        "    # print('whole loss is %.5f'%(whole_loss_t/925))\n",
        "    # with open(\"training_data/wer_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "    #     f.write(\"%s\\n\" % (str(wer)))\n",
        "\n",
        "    if (sacc > exprate):\n",
        "        exprate = sacc\n",
        "        print(exprate)\n",
        "        print(\"saving the model....\")\n",
        "        print('encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl' %(lr_rate))\n",
        "        torch.save(encoder.state_dict(), f'{PATH}model/encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl'%(lr_rate))\n",
        "        torch.save(attn_decoder1.state_dict(), f'{PATH}model/attn_decoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl'%(lr_rate))\n",
        "        print(\"done\")\n",
        "        flag = 0\n",
        "    else:\n",
        "        flag = flag+1\n",
        "        print('the best is %f' % (exprate))\n",
        "        print('the loss is bigger than before,so do not save the model')\n",
        "\n",
        "    if flag == 10:\n",
        "        lr_rate = lr_rate*0.1\n",
        "        flag = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 1.436%, running_loss is 106.078320\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 2.871%, running_loss is 63.507302\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 4.307%, running_loss is 62.860098\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 5.742%, running_loss is 54.887979\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 7.178%, running_loss is 48.288762\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 8.613%, running_loss is 42.481473\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 10.049%, running_loss is 46.712585\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 11.485%, running_loss is 43.473021\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 12.920%, running_loss is 43.491725\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 14.356%, running_loss is 41.640870\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 15.791%, running_loss is 41.599255\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 17.227%, running_loss is 39.421331\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 18.663%, running_loss is 40.013130\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 20.098%, running_loss is 38.266284\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 21.534%, running_loss is 38.104192\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 22.969%, running_loss is 40.680426\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 24.405%, running_loss is 37.593781\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 25.840%, running_loss is 37.042961\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 27.276%, running_loss is 42.285587\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 28.712%, running_loss is 37.588597\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 30.147%, running_loss is 35.653957\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 31.583%, running_loss is 38.441905\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 33.018%, running_loss is 36.803083\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 34.454%, running_loss is 38.812094\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 35.889%, running_loss is 37.467400\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 37.325%, running_loss is 36.708311\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 38.761%, running_loss is 37.334078\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 40.196%, running_loss is 34.179202\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 41.632%, running_loss is 34.530421\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 43.067%, running_loss is 35.630766\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 44.503%, running_loss is 35.993007\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 45.939%, running_loss is 34.521885\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 47.374%, running_loss is 38.560772\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 48.810%, running_loss is 36.704367\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 50.245%, running_loss is 36.330471\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 51.681%, running_loss is 35.381887\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 53.116%, running_loss is 34.430052\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 54.552%, running_loss is 38.386138\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 55.988%, running_loss is 35.553357\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 57.423%, running_loss is 35.234444\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 58.859%, running_loss is 34.789952\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 60.294%, running_loss is 33.375288\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 61.730%, running_loss is 35.305697\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 63.165%, running_loss is 32.817695\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 64.601%, running_loss is 36.645142\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 66.037%, running_loss is 34.163120\n",
            "epoch is 0, lr rate is 0.00500, te is 1.000, batch_size is 6, loading for 67.472%, running_loss is 33.039576\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}