{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKlVVHh19aK",
        "outputId": "34b0ad5a-a402-44ee-f90f-50a173644659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhu_7Apj3OtE"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Math_to_latex')\n",
        "print(sys.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDi7vhcu1z1g"
      },
      "source": [
        "'''\n",
        "Python 3.6 \n",
        "Pytorch >= 0.4\n",
        "Written by Hongyu Wang in Beihang university\n",
        "'''\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy\n",
        "import torch.utils.data as data\n",
        "from data_iterator import dataIterator\n",
        "from Densenet_torchvision import densenet121\n",
        "from Attention_RNN import AttnDecoderRNN\n",
        "#from Resnet101 import resnet101\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "# if __name__ == '__main__':\n",
        "#     freeze_support()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZlFifO13icM"
      },
      "source": [
        "gpu = torch.cuda.current_device()\n",
        "print(gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsClwMF51z1q"
      },
      "source": [
        "# compute the wer loss\n",
        "def cmp_result(label,rec):\n",
        "    dist_mat = numpy.zeros((len(label)+1, len(rec)+1),dtype='int32')\n",
        "    dist_mat[0,:] = range(len(rec) + 1)\n",
        "    dist_mat[:,0] = range(len(label) + 1)\n",
        "    for i in range(1, len(label) + 1):\n",
        "        for j in range(1, len(rec) + 1):\n",
        "            hit_score = dist_mat[i-1, j-1] + (label[i-1] != rec[j-1])\n",
        "            ins_score = dist_mat[i,j-1] + 1\n",
        "            del_score = dist_mat[i-1, j] + 1\n",
        "            dist_mat[i,j] = min(hit_score, ins_score, del_score)\n",
        "    dist = dist_mat[len(label), len(rec)]\n",
        "    return dist, len(label)\n",
        "\n",
        "def load_dict(dictFile):\n",
        "    fp=open(dictFile)\n",
        "    stuff=fp.readlines()\n",
        "    fp.close()\n",
        "    lexicon={}\n",
        "    for l in stuff:\n",
        "        w=l.strip().split()\n",
        "        lexicon[w[0]]=int(w[1])\n",
        "    print('total words/phones',len(lexicon))\n",
        "    return lexicon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezuzFh91z19"
      },
      "source": [
        "PATH = '/content/drive/My Drive/Math_to_latex/'\n",
        "datasets=[f'{PATH}offline-train.pkl',f'{PATH}/train_caption.txt']\n",
        "valid_datasets=[f'{PATH}offline-test.pkl', f'{PATH}test_caption.txt']\n",
        "dictionaries=[f'{PATH}dictionary.txt']\n",
        "batch_Imagesize=500000\n",
        "valid_batch_Imagesize=500000\n",
        "# batch_size for training and testing\n",
        "batch_size=6\n",
        "batch_size_t=6\n",
        "# the max (label length/Image size) in training and testing\n",
        "# you can change 'maxlen','maxImagesize' by the size of your GPU\n",
        "maxlen=48\n",
        "maxImagesize= 100000\n",
        "# hidden_size in RNN\n",
        "hidden_size = 256\n",
        "# teacher_forcing_ratio \n",
        "teacher_forcing_ratio = 1\n",
        "# change the gpu id \n",
        "gpu = [0,1]\n",
        "# learning rate\n",
        "# lr_rate = 0.0001\n",
        "lr_rate = 0.001\n",
        "# flag to remember when to change the learning rate\n",
        "flag = 0\n",
        "# exprate\n",
        "exprate = 0\n",
        "\n",
        "# worddicts\n",
        "worddicts = load_dict(dictionaries[0])\n",
        "worddicts_r = [None] * len(worddicts)\n",
        "for kk, vv in worddicts.items():\n",
        "        worddicts_r[vv] = kk\n",
        "\n",
        "#load train data and test data\n",
        "train,train_label = dataIterator(\n",
        "                                    datasets[0], datasets[1],worddicts,batch_size=1,\n",
        "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
        "                                 )\n",
        "len_train = len(train)\n",
        "\n",
        "test,test_label = dataIterator(\n",
        "                                    valid_datasets[0],valid_datasets[1],worddicts,batch_size=1,\n",
        "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
        "                                )\n",
        "len_test = len(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D97Gj3QK1z2F"
      },
      "source": [
        "class custom_dset(data.Dataset):\n",
        "    def __init__(self,train,train_label,batch_size):\n",
        "        self.train = train\n",
        "        self.train_label = train_label\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        train_setting = torch.from_numpy(numpy.array(self.train[index]))\n",
        "        label_setting = torch.from_numpy(numpy.array(self.train_label[index])).type(torch.LongTensor)\n",
        "\n",
        "        size = train_setting.size()\n",
        "        train_setting = train_setting.view(1,size[2],size[3])\n",
        "        label_setting = label_setting.view(-1)\n",
        "        return train_setting,label_setting\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train)\n",
        "\n",
        "\n",
        "off_image_train = custom_dset(train,train_label,batch_size)\n",
        "off_image_test = custom_dset(test,test_label,batch_size)\n",
        "\n",
        "# collate_fn is writting for padding imgs in batch. \n",
        "# As images in my dataset are different size, so the padding is necessary.\n",
        "# Padding images to the max image size in a mini-batch and cat a mask. \n",
        "def collate_fn(batch):\n",
        "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
        "    img, label = zip(*batch)\n",
        "    aa1 = 0\n",
        "    bb1 = 0\n",
        "    k = 0\n",
        "    k1 = 0\n",
        "    max_len = len(label[0])+1\n",
        "    for j in range(len(img)):\n",
        "        size = img[j].size()\n",
        "        if size[1] > aa1:\n",
        "            aa1 = size[1]\n",
        "        if size[2] > bb1:\n",
        "            bb1 = size[2]\n",
        "\n",
        "    for ii in img:\n",
        "        ii = ii.float()\n",
        "        img_size_h = ii.size()[1]\n",
        "        img_size_w = ii.size()[2]\n",
        "        img_mask_sub_s = torch.ones(1,img_size_h,img_size_w).type(torch.FloatTensor)\n",
        "        img_mask_sub_s = img_mask_sub_s*255.0\n",
        "        img_mask_sub = torch.cat((ii,img_mask_sub_s),dim=0)\n",
        "        padding_h = aa1-img_size_h\n",
        "        padding_w = bb1-img_size_w\n",
        "        m = torch.nn.ZeroPad2d((0,padding_w,0,padding_h))\n",
        "        img_mask_sub_padding = m(img_mask_sub)\n",
        "        img_mask_sub_padding = img_mask_sub_padding.unsqueeze(0)\n",
        "        if k==0:\n",
        "            img_padding_mask = img_mask_sub_padding\n",
        "        else:\n",
        "            img_padding_mask = torch.cat((img_padding_mask,img_mask_sub_padding),dim=0)\n",
        "        k = k+1\n",
        "\n",
        "    for ii1 in label:\n",
        "        ii1 = ii1.long()\n",
        "        ii1 = ii1.unsqueeze(0)\n",
        "        ii1_len = ii1.size()[1]\n",
        "        m = torch.nn.ZeroPad2d((0,max_len-ii1_len,0,0))\n",
        "        ii1_padding = m(ii1)\n",
        "        if k1 == 0:\n",
        "            label_padding = ii1_padding\n",
        "        else:\n",
        "            label_padding = torch.cat((label_padding,ii1_padding),dim=0)\n",
        "        k1 = k1+1\n",
        "\n",
        "    img_padding_mask = img_padding_mask/255.0\n",
        "    return img_padding_mask, label_padding\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = off_image_train,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    # num_workers=2,\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = off_image_test,\n",
        "    batch_size = batch_size_t,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    # num_workers=2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41v3UxF71z2K"
      },
      "source": [
        "def my_train(target_length,attn_decoder1,\n",
        "             output_highfeature, output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
        "             decoder_input,decoder_hidden,attention_sum,decoder_attention):\n",
        "    loss = 0\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    flag_z = [0]*batch_size\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        encoder_optimizer1.zero_grad()\n",
        "        decoder_optimizer1.zero_grad()\n",
        "        my_num = 0\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention, attention_sum = attn_decoder1(decoder_input,\n",
        "                                                                                             decoder_hidden,\n",
        "                                                                                             output_highfeature,\n",
        "                                                                                             output_area,\n",
        "                                                                                             attention_sum,\n",
        "                                                                                             decoder_attention,\n",
        "                                                                                             dense_input,batch_size,h_mask,w_mask,gpu)\n",
        "            \n",
        "            \n",
        "            #print(decoder_output.size()) (batch,1,112)\n",
        "            y = y.unsqueeze(0)\n",
        "            for i in range(batch_size):\n",
        "                if int(y[0][i][di]) == 0:\n",
        "                    flag_z[i] = flag_z[i]+1\n",
        "                    if flag_z[i] > 1:\n",
        "                        continue\n",
        "                    else:\n",
        "                        loss += criterion(decoder_output[i], y[:,i,di])\n",
        "                else:\n",
        "                    loss += criterion(decoder_output[i], y[:,i,di])\n",
        "\n",
        "            if int(y[0][0][di]) == 0:\n",
        "                break\n",
        "            decoder_input = y[:,:,di]\n",
        "            decoder_input = decoder_input.squeeze(0)\n",
        "            y = y.squeeze(0)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer1.step()\n",
        "        decoder_optimizer1.step()\n",
        "        return loss.item()\n",
        "\n",
        "    else:\n",
        "        encoder_optimizer1.zero_grad()\n",
        "        decoder_optimizer1.zero_grad()\n",
        "        my_num = 0\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention,attention_sum= attn_decoder1(decoder_input, decoder_hidden,\n",
        "                                                                                output_highfeature, output_area,\n",
        "                                                                                attention_sum,decoder_attention,dense_input,batch_size,\n",
        "                                                                                h_mask,w_mask,gpu)\n",
        "            #print(decoder_output.size()) 1*10*112\n",
        "            #print(y.size())  1*37\n",
        "            #topi (b,1)\n",
        "            topv,topi = torch.max(decoder_output,2)\n",
        "            decoder_input = topi\n",
        "            decoder_input = decoder_input.view(batch_size)\n",
        "\n",
        "            y = y.unsqueeze(0)\n",
        "            #print(y_t)\n",
        "\n",
        "            # 1*bs*17\n",
        "            for k in range(batch_size):\n",
        "                if int(y[0][k][di]) == 0:\n",
        "                    flag_z[k] = flag_z[k]+1\n",
        "                    if flag_z[k] > 1:\n",
        "                        continue\n",
        "                    else:\n",
        "                        loss += criterion(decoder_output[k], y[:,k,di])\n",
        "                else:\n",
        "                    loss += criterion(decoder_output[k], y[:,k,di])\n",
        "\n",
        "            y = y.squeeze(0)\n",
        "            # if int(topi[0]) == 0:\n",
        "            #     break\n",
        "        loss.backward()\n",
        "        encoder_optimizer1.step()\n",
        "        decoder_optimizer1.step()\n",
        "        return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2k8uTbz313W"
      },
      "source": [
        "gpu = [torch.cuda.current_device()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVuKzMZe1z2V"
      },
      "source": [
        "encoder = densenet121()\n",
        "\n",
        "pthfile = f'{PATH}densenet121-a639ec97.pth'\n",
        "pretrained_dict = torch.load(pthfile) \n",
        "encoder_dict = encoder.state_dict()\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in encoder_dict}\n",
        "encoder_dict.update(pretrained_dict)\n",
        "encoder.load_state_dict(encoder_dict)\n",
        "\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size,112,dropout_p=0.5)\n",
        "\n",
        "encoder=encoder.cuda() #gpu\n",
        "attn_decoder1 = attn_decoder1.cuda()\n",
        "encoder = torch.nn.DataParallel(encoder, device_ids=gpu)\n",
        "attn_decoder1 = torch.nn.DataParallel(attn_decoder1, device_ids=gpu)\n",
        "\n",
        "# encoder = torch.nn.DataParallel(encoder)\n",
        "# attn_decoder1 = torch.nn.DataParallel(attn_decoder1)\n",
        "attn_decoder1.load_state_dict(torch.load(f'{PATH}model/attn_decoder_v1.pkl'))\n",
        "encoder.load_state_dict(torch.load(f'{PATH}model/encoder_v1.pkl'))\n",
        "\n",
        "def imresize(im,sz):\n",
        "    pil_im = Image.fromarray(im)\n",
        "    return numpy.array(pil_im.resize(sz))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrkb8nKbew80"
      },
      "source": [
        "# this is the prediction and compute wer loss\n",
        "total_dist = 0\n",
        "total_label = 0\n",
        "total_line = 0\n",
        "total_line_rec = 0\n",
        "whole_loss_t = 0\n",
        "\n",
        "encoder.eval()\n",
        "attn_decoder1.eval()\n",
        "print('Now, begin testing!!')\n",
        "\n",
        "#     for step_t, (x_t, y_t) in tqdm(enumerate(test_loader)):\n",
        "for step_t, (x_t, y_t) in enumerate(test_loader):\n",
        "  x_real_high = x_t.size()[2]\n",
        "  x_real_width = x_t.size()[3]\n",
        "  if x_t.size()[0]<batch_size_t:\n",
        "      break\n",
        "  print('testing for %.3f%%'%(step_t*100*batch_size_t/len_test),end='\\r')\n",
        "  h_mask_t = []\n",
        "  w_mask_t = []\n",
        "  for i in x_t:\n",
        "      #h*w\n",
        "      size_mask_t = i[1].size()\n",
        "      s_w_t = str(i[1][0])\n",
        "      s_h_t = str(i[1][:,1])\n",
        "      w_t = s_w_t.count('1')\n",
        "      h_t = s_h_t.count('1')\n",
        "      h_comp_t = int(h_t/16)+1\n",
        "      w_comp_t = int(w_t/16)+1\n",
        "      h_mask_t.append(h_comp_t)\n",
        "      w_mask_t.append(w_comp_t)\n",
        "\n",
        "  x_t = x_t.cuda()\n",
        "  y_t = y_t.cuda()\n",
        "  output_highfeature_t = encoder(x_t)\n",
        "\n",
        "  x_mean_t = torch.mean(output_highfeature_t)\n",
        "  x_mean_t = float(x_mean_t)\n",
        "  output_area_t1 = output_highfeature_t.size()\n",
        "  output_area_t = output_area_t1[3]\n",
        "  dense_input = output_area_t1[2]\n",
        "\n",
        "  decoder_input_t = torch.LongTensor([111]*batch_size_t)\n",
        "  decoder_input_t = decoder_input_t.cuda()\n",
        "  decoder_hidden_t = torch.randn(batch_size_t, 1, hidden_size).cuda()\n",
        "  nn.init.xavier_uniform_(decoder_hidden_t)\n",
        "\n",
        "  x_mean_t=[]\n",
        "  for i in output_highfeature_t:\n",
        "      x_mean_t.append(float(torch.mean(i)))\n",
        "  # x_mean = torch.mean(output_highfeature)\n",
        "  # x_mean = float(x_mean)\n",
        "  for i in range(batch_size_t):\n",
        "      decoder_hidden_t[i] = decoder_hidden_t[i]*x_mean_t[i]\n",
        "      decoder_hidden_t[i] = torch.tanh(decoder_hidden_t[i])\n",
        "\n",
        "  prediction = torch.zeros(batch_size_t,maxlen)\n",
        "  #label = torch.zeros(batch_size_t,maxlen)\n",
        "  prediction_sub = []\n",
        "  label_sub = []\n",
        "  decoder_attention_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "  attention_sum_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "  flag_z_t = [0]*batch_size_t\n",
        "  loss_t = 0\n",
        "  m = torch.nn.ZeroPad2d((0,maxlen-y_t.size()[1],0,0))\n",
        "  y_t = m(y_t)\n",
        "  for i in range(maxlen):\n",
        "      decoder_output, decoder_hidden_t, decoder_attention_t, attention_sum_t = attn_decoder1(decoder_input_t,\n",
        "                                                                                        decoder_hidden_t,\n",
        "                                                                                        output_highfeature_t,\n",
        "                                                                                        output_area_t,\n",
        "                                                                                        attention_sum_t,\n",
        "                                                                                        decoder_attention_t,dense_input,batch_size_t,h_mask_t,w_mask_t,gpu)\n",
        "\n",
        "      ### you can see the attention when testing\n",
        "\n",
        "      # print('this is',i)\n",
        "      # for i in range(batch_size_t):\n",
        "      #     x_real = numpy.array(x_t[i][0].data.cpu())\n",
        "\n",
        "      #     show = numpy.array(decoder_attention_t[i][0].data.cpu())\n",
        "      #     show = imresize(show,(x_real_width,x_real_high))\n",
        "      #     k_max = show.max()\n",
        "      #     show = show/k_max\n",
        "\n",
        "      #     show_x = x_real+show\n",
        "      #     plt.imshow(show_x, interpolation='nearest', cmap='gray_r')\n",
        "      #     plt.show()\n",
        "      \n",
        "      topv,topi = torch.max(decoder_output,2)\n",
        "      # if torch.sum(y_t[0,:,i])==0:\n",
        "      #     y_t = y_t.squeeze(0)\n",
        "      #     break\n",
        "      if torch.sum(topi)==0:\n",
        "          break\n",
        "      decoder_input_t = topi\n",
        "      decoder_input_t = decoder_input_t.view(batch_size_t)\n",
        "\n",
        "      # prediction\n",
        "      prediction[:,i] = decoder_input_t\n",
        "\n",
        "  for i in range(batch_size_t):\n",
        "      for j in range(maxlen):\n",
        "          if int(prediction[i][j]) ==0:\n",
        "              break\n",
        "          else:\n",
        "              prediction_sub.append(int(prediction[i][j]))\n",
        "      if len(prediction_sub)<maxlen:\n",
        "          prediction_sub.append(0)\n",
        "\n",
        "      for k in range(y_t.size()[1]):\n",
        "          if int(y_t[i][k]) ==0:\n",
        "              break\n",
        "          else:\n",
        "              label_sub.append(int(y_t[i][k]))\n",
        "      label_sub.append(0)\n",
        "\n",
        "      dist, llen = cmp_result(label_sub, prediction_sub)\n",
        "      total_dist += dist\n",
        "      total_label += llen\n",
        "      total_line += 1\n",
        "      if dist == 0:\n",
        "          total_line_rec = total_line_rec+ 1\n",
        "\n",
        "      label_sub = []\n",
        "      prediction_sub = []\n",
        "\n",
        "print('total_line_rec is',total_line_rec)\n",
        "wer = float(total_dist) / total_label\n",
        "sacc = float(total_line_rec) / total_line\n",
        "print('wer is %.5f' % (wer))\n",
        "print('sacc is %.5f ' % (sacc))\n",
        "# print('whole loss is %.5f'%(whole_loss_t/925))\n",
        "# with open(\"training_data/wer_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "#     f.write(\"%s\\n\" % (str(wer)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEVf1EdMmIJC"
      },
      "source": [
        "lr_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ4hWX0x1z2c"
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "\n",
        "decoder_input_init = torch.LongTensor([111]*batch_size).cuda() #gpu\n",
        "decoder_hidden_init = torch.randn(batch_size, 1, hidden_size).cuda()\n",
        "# decoder_input_init = torch.LongTensor([111]*batch_size)\n",
        "# decoder_hidden_init = torch.randn(batch_size, 1, hidden_size)\n",
        "nn.init.xavier_uniform_(decoder_hidden_init)\n",
        "\n",
        "encoder_optimizer1 = torch.optim.Adam(encoder.parameters(), lr=lr_rate)\n",
        "decoder_optimizer1 = torch.optim.Adam(attn_decoder1.parameters(), lr=lr_rate)\n",
        "\n",
        "for epoch in tqdm(range(5)):\n",
        "#     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "#     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "\n",
        "    # # if using SGD optimizer\n",
        "    # if epoch+1 == 50:\n",
        "    #     lr_rate = lr_rate/10\n",
        "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    # if epoch+1 == 75:\n",
        "    #     lr_rate = lr_rate/10\n",
        "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    whole_loss = 0\n",
        "\n",
        "    encoder.train(mode=True)\n",
        "    attn_decoder1.train(mode=True)\n",
        "\n",
        "    # this is the train\n",
        "#     for step,(x,y) in tqdm(enumerate(train_loader)):\n",
        "    for step,(x,y) in enumerate(train_loader):\n",
        "        if x.size()[0]<batch_size:\n",
        "            break\n",
        "        h_mask = []\n",
        "        w_mask = []\n",
        "        for i in x:\n",
        "            #h*w\n",
        "            size_mask = i[1].size()\n",
        "            s_w = str(i[1][0])\n",
        "            s_h = str(i[1][:,1])\n",
        "            w = s_w.count('1')\n",
        "            h = s_h.count('1')\n",
        "            h_comp = int(h/16)+1\n",
        "            w_comp = int(w/16)+1\n",
        "            h_mask.append(h_comp)\n",
        "            w_mask.append(w_comp)\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        # out is CNN featuremaps\n",
        "        output_highfeature = encoder(x)\n",
        "        x_mean=[]\n",
        "        for i in output_highfeature:\n",
        "            x_mean.append(float(torch.mean(i)))\n",
        "        # x_mean = torch.mean(output_highfeature)\n",
        "        # x_mean = float(x_mean)\n",
        "        for i in range(batch_size):\n",
        "            decoder_hidden_init[i] = decoder_hidden_init[i]*x_mean[i]\n",
        "            decoder_hidden_init[i] = torch.tanh(decoder_hidden_init[i])\n",
        "\n",
        "        # dense_input is height and output_area is width which is bb\n",
        "        output_area1 = output_highfeature.size()\n",
        "\n",
        "        output_area = output_area1[3]\n",
        "        dense_input = output_area1[2]\n",
        "        target_length = y.size()[1]\n",
        "        attention_sum_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
        "        decoder_attention_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
        "\n",
        "        running_loss += my_train(target_length,attn_decoder1,output_highfeature,\n",
        "                                output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
        "                                decoder_input_init,decoder_hidden_init,attention_sum_init,decoder_attention_init)\n",
        "\n",
        "        \n",
        "        if step % 20 == 19:\n",
        "            pre = ((step+1)/len_train)*100*batch_size\n",
        "            whole_loss += running_loss\n",
        "            running_loss = running_loss/(batch_size*20)\n",
        "            print('epoch is %d, lr rate is %.5f, te is %.3f, batch_size is %d, loading for %.3f%%, running_loss is %f' %(epoch,lr_rate,teacher_forcing_ratio, batch_size,pre,running_loss))\n",
        "            # with open(\"training_data/running_loss_%.5f_pre_GN_te05_d02_all.txt\" %(lr_rate),\"a\") as f:\n",
        "            #     f.write(\"%s\\n\"%(str(running_loss)))\n",
        "            running_loss = 0\n",
        "\n",
        "    loss_all_out = whole_loss / len_train\n",
        "    print(\"epoch is %d, the whole loss is %f\" % (epoch, loss_all_out))\n",
        "    # with open(\"training_data/whole_loss_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "    #     f.write(\"%s\\n\" % (str(loss_all_out)))\n",
        "\n",
        "    # this is the prediction and compute wer loss\n",
        "    total_dist = 0\n",
        "    total_label = 0\n",
        "    total_line = 0\n",
        "    total_line_rec = 0\n",
        "    whole_loss_t = 0\n",
        "\n",
        "    encoder.eval()\n",
        "    attn_decoder1.eval()\n",
        "    print('Now, begin testing!!')\n",
        "\n",
        "#     for step_t, (x_t, y_t) in tqdm(enumerate(test_loader)):\n",
        "    for step_t, (x_t, y_t) in enumerate(test_loader):\n",
        "        x_real_high = x_t.size()[2]\n",
        "        x_real_width = x_t.size()[3]\n",
        "        if x_t.size()[0]<batch_size_t:\n",
        "            break\n",
        "        print('testing for %.3f%%'%(step_t*100*batch_size_t/len_test),end='\\r')\n",
        "        h_mask_t = []\n",
        "        w_mask_t = []\n",
        "        for i in x_t:\n",
        "            #h*w\n",
        "            size_mask_t = i[1].size()\n",
        "            s_w_t = str(i[1][0])\n",
        "            s_h_t = str(i[1][:,1])\n",
        "            w_t = s_w_t.count('1')\n",
        "            h_t = s_h_t.count('1')\n",
        "            h_comp_t = int(h_t/16)+1\n",
        "            w_comp_t = int(w_t/16)+1\n",
        "            h_mask_t.append(h_comp_t)\n",
        "            w_mask_t.append(w_comp_t)\n",
        "\n",
        "        x_t = x_t.cuda()\n",
        "        y_t = y_t.cuda()\n",
        "        output_highfeature_t = encoder(x_t)\n",
        "\n",
        "        x_mean_t = torch.mean(output_highfeature_t)\n",
        "        x_mean_t = float(x_mean_t)\n",
        "        output_area_t1 = output_highfeature_t.size()\n",
        "        output_area_t = output_area_t1[3]\n",
        "        dense_input = output_area_t1[2]\n",
        "\n",
        "        decoder_input_t = torch.LongTensor([111]*batch_size_t)\n",
        "        decoder_input_t = decoder_input_t.cuda()\n",
        "        decoder_hidden_t = torch.randn(batch_size_t, 1, hidden_size).cuda()\n",
        "        nn.init.xavier_uniform_(decoder_hidden_t)\n",
        "\n",
        "        x_mean_t=[]\n",
        "        for i in output_highfeature_t:\n",
        "            x_mean_t.append(float(torch.mean(i)))\n",
        "        # x_mean = torch.mean(output_highfeature)\n",
        "        # x_mean = float(x_mean)\n",
        "        for i in range(batch_size_t):\n",
        "            decoder_hidden_t[i] = decoder_hidden_t[i]*x_mean_t[i]\n",
        "            decoder_hidden_t[i] = torch.tanh(decoder_hidden_t[i])\n",
        "\n",
        "        prediction = torch.zeros(batch_size_t,maxlen)\n",
        "        #label = torch.zeros(batch_size_t,maxlen)\n",
        "        prediction_sub = []\n",
        "        label_sub = []\n",
        "        decoder_attention_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "        attention_sum_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "        flag_z_t = [0]*batch_size_t\n",
        "        loss_t = 0\n",
        "        m = torch.nn.ZeroPad2d((0,maxlen-y_t.size()[1],0,0))\n",
        "        y_t = m(y_t)\n",
        "        for i in range(maxlen):\n",
        "            decoder_output, decoder_hidden_t, decoder_attention_t, attention_sum_t = attn_decoder1(decoder_input_t,\n",
        "                                                                                             decoder_hidden_t,\n",
        "                                                                                             output_highfeature_t,\n",
        "                                                                                             output_area_t,\n",
        "                                                                                             attention_sum_t,\n",
        "                                                                                             decoder_attention_t,dense_input,batch_size_t,h_mask_t,w_mask_t,gpu)\n",
        "\n",
        "            ### you can see the attention when testing\n",
        "\n",
        "            # print('this is',i)\n",
        "            # for i in range(batch_size_t):\n",
        "            #     x_real = numpy.array(x_t[i][0].data.cpu())\n",
        "\n",
        "            #     show = numpy.array(decoder_attention_t[i][0].data.cpu())\n",
        "            #     show = imresize(show,(x_real_width,x_real_high))\n",
        "            #     k_max = show.max()\n",
        "            #     show = show/k_max\n",
        "\n",
        "            #     show_x = x_real+show\n",
        "            #     plt.imshow(show_x, interpolation='nearest', cmap='gray_r')\n",
        "            #     plt.show()\n",
        "            \n",
        "            topv,topi = torch.max(decoder_output,2)\n",
        "            # if torch.sum(y_t[0,:,i])==0:\n",
        "            #     y_t = y_t.squeeze(0)\n",
        "            #     break\n",
        "            if torch.sum(topi)==0:\n",
        "                break\n",
        "            decoder_input_t = topi\n",
        "            decoder_input_t = decoder_input_t.view(batch_size_t)\n",
        "\n",
        "            # prediction\n",
        "            prediction[:,i] = decoder_input_t\n",
        "\n",
        "        for i in range(batch_size_t):\n",
        "            for j in range(maxlen):\n",
        "                if int(prediction[i][j]) ==0:\n",
        "                    break\n",
        "                else:\n",
        "                    prediction_sub.append(int(prediction[i][j]))\n",
        "            if len(prediction_sub)<maxlen:\n",
        "                prediction_sub.append(0)\n",
        "\n",
        "            for k in range(y_t.size()[1]):\n",
        "                if int(y_t[i][k]) ==0:\n",
        "                    break\n",
        "                else:\n",
        "                    label_sub.append(int(y_t[i][k]))\n",
        "            label_sub.append(0)\n",
        "\n",
        "            dist, llen = cmp_result(label_sub, prediction_sub)\n",
        "            total_dist += dist\n",
        "            total_label += llen\n",
        "            total_line += 1\n",
        "            if dist == 0:\n",
        "                total_line_rec = total_line_rec+ 1\n",
        "\n",
        "            label_sub = []\n",
        "            prediction_sub = []\n",
        "\n",
        "    print('total_line_rec is',total_line_rec)\n",
        "    wer = float(total_dist) / total_label\n",
        "    sacc = float(total_line_rec) / total_line\n",
        "    print('wer is %.5f' % (wer))\n",
        "    print('sacc is %.5f ' % (sacc))\n",
        "    # print('whole loss is %.5f'%(whole_loss_t/925))\n",
        "    # with open(\"training_data/wer_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "    #     f.write(\"%s\\n\" % (str(wer)))\n",
        "\n",
        "    if (sacc > exprate):\n",
        "        exprate = sacc\n",
        "        print(exprate)\n",
        "        print(\"saving the model....\")\n",
        "        print('encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl' %(lr_rate))\n",
        "        torch.save(encoder.state_dict(), f'{PATH}model/encoder_v2.pkl')\n",
        "        torch.save(attn_decoder1.state_dict(), f'{PATH}model/attn_decoder_v2.pkl')\n",
        "        print(\"done\")\n",
        "        flag = 0\n",
        "    else:\n",
        "        flag = flag+1\n",
        "        print('the best is %f' % (exprate))\n",
        "        print('the loss is bigger than before,so do not save the model')\n",
        "\n",
        "    if flag == 10:\n",
        "        lr_rate = lr_rate*0.1\n",
        "        flag = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIip6qBynGqX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}