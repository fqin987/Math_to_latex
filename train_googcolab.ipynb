{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwKlVVHh19aK",
        "outputId": "c690adf1-0165-450d-99a8-1af6789b618d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhu_7Apj3OtE",
        "outputId": "f2cfc1cc-c64f-4721-9f10-dd8cb00e1190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Math_to_latex')\n",
        "print(sys.path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', '/content/drive/My Drive/Math_to_latex']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDi7vhcu1z1g"
      },
      "source": [
        "'''\n",
        "Python 3.6 \n",
        "Pytorch >= 0.4\n",
        "Written by Hongyu Wang in Beihang university\n",
        "'''\n",
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy\n",
        "import torch.utils.data as data\n",
        "from data_iterator import dataIterator\n",
        "from Densenet_torchvision import densenet121\n",
        "from Attention_RNN import AttnDecoderRNN\n",
        "#from Resnet101 import resnet101\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "# if __name__ == '__main__':\n",
        "#     freeze_support()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZlFifO13icM",
        "outputId": "6e583445-5790-4b0f-bec8-0157b4c5e04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gpu = torch.cuda.current_device()\n",
        "print(gpu)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsClwMF51z1q"
      },
      "source": [
        "# compute the wer loss\n",
        "def cmp_result(label,rec):\n",
        "    dist_mat = numpy.zeros((len(label)+1, len(rec)+1),dtype='int32')\n",
        "    dist_mat[0,:] = range(len(rec) + 1)\n",
        "    dist_mat[:,0] = range(len(label) + 1)\n",
        "    for i in range(1, len(label) + 1):\n",
        "        for j in range(1, len(rec) + 1):\n",
        "            hit_score = dist_mat[i-1, j-1] + (label[i-1] != rec[j-1])\n",
        "            ins_score = dist_mat[i,j-1] + 1\n",
        "            del_score = dist_mat[i-1, j] + 1\n",
        "            dist_mat[i,j] = min(hit_score, ins_score, del_score)\n",
        "    dist = dist_mat[len(label), len(rec)]\n",
        "    return dist, len(label)\n",
        "\n",
        "def load_dict(dictFile):\n",
        "    fp=open(dictFile)\n",
        "    stuff=fp.readlines()\n",
        "    fp.close()\n",
        "    lexicon={}\n",
        "    for l in stuff:\n",
        "        w=l.strip().split()\n",
        "        lexicon[w[0]]=int(w[1])\n",
        "    print('total words/phones',len(lexicon))\n",
        "    return lexicon"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezuzFh91z19",
        "outputId": "c5951e92-39c2-4b67-b4e4-274bd3ef8b97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "PATH = '/content/drive/My Drive/Math_to_latex/'\n",
        "datasets=[f'{PATH}offline-train.pkl',f'{PATH}/train_caption.txt']\n",
        "valid_datasets=[f'{PATH}offline-test.pkl', f'{PATH}test_caption.txt']\n",
        "dictionaries=[f'{PATH}dictionary.txt']\n",
        "batch_Imagesize=500000\n",
        "valid_batch_Imagesize=500000\n",
        "# batch_size for training and testing\n",
        "batch_size=6\n",
        "batch_size_t=6\n",
        "# the max (label length/Image size) in training and testing\n",
        "# you can change 'maxlen','maxImagesize' by the size of your GPU\n",
        "maxlen=48\n",
        "maxImagesize= 100000\n",
        "# hidden_size in RNN\n",
        "hidden_size = 256\n",
        "# teacher_forcing_ratio \n",
        "teacher_forcing_ratio = 1\n",
        "# change the gpu id \n",
        "gpu = [0,1]\n",
        "# learning rate\n",
        "# lr_rate = 0.0001\n",
        "lr_rate = 0.001\n",
        "# flag to remember when to change the learning rate\n",
        "flag = 0\n",
        "# exprate\n",
        "exprate = 0\n",
        "\n",
        "# worddicts\n",
        "worddicts = load_dict(dictionaries[0])\n",
        "worddicts_r = [None] * len(worddicts)\n",
        "for kk, vv in worddicts.items():\n",
        "        worddicts_r[vv] = kk\n",
        "\n",
        "#load train data and test data\n",
        "train,train_label = dataIterator(\n",
        "                                    datasets[0], datasets[1],worddicts,batch_size=1,\n",
        "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
        "                                 )\n",
        "len_train = len(train)\n",
        "\n",
        "test,test_label = dataIterator(\n",
        "                                    valid_datasets[0],valid_datasets[1],worddicts,batch_size=1,\n",
        "                                    batch_Imagesize=batch_Imagesize,maxlen=maxlen,maxImagesize=maxImagesize\n",
        "                                )\n",
        "len_test = len(test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total words/phones 112\n",
            "total  8359 batch data loaded\n",
            "ignore 476 images\n",
            "total  925 batch data loaded\n",
            "ignore 61 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D97Gj3QK1z2F"
      },
      "source": [
        "class custom_dset(data.Dataset):\n",
        "    def __init__(self,train,train_label,batch_size):\n",
        "        self.train = train\n",
        "        self.train_label = train_label\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        train_setting = torch.from_numpy(numpy.array(self.train[index]))\n",
        "        label_setting = torch.from_numpy(numpy.array(self.train_label[index])).type(torch.LongTensor)\n",
        "\n",
        "        size = train_setting.size()\n",
        "        train_setting = train_setting.view(1,size[2],size[3])\n",
        "        label_setting = label_setting.view(-1)\n",
        "        return train_setting,label_setting\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train)\n",
        "\n",
        "\n",
        "off_image_train = custom_dset(train,train_label,batch_size)\n",
        "off_image_test = custom_dset(test,test_label,batch_size)\n",
        "\n",
        "# collate_fn is writting for padding imgs in batch. \n",
        "# As images in my dataset are different size, so the padding is necessary.\n",
        "# Padding images to the max image size in a mini-batch and cat a mask. \n",
        "def collate_fn(batch):\n",
        "    batch.sort(key=lambda x: len(x[1]), reverse=True)\n",
        "    img, label = zip(*batch)\n",
        "    aa1 = 0\n",
        "    bb1 = 0\n",
        "    k = 0\n",
        "    k1 = 0\n",
        "    max_len = len(label[0])+1\n",
        "    for j in range(len(img)):\n",
        "        size = img[j].size()\n",
        "        if size[1] > aa1:\n",
        "            aa1 = size[1]\n",
        "        if size[2] > bb1:\n",
        "            bb1 = size[2]\n",
        "\n",
        "    for ii in img:\n",
        "        ii = ii.float()\n",
        "        img_size_h = ii.size()[1]\n",
        "        img_size_w = ii.size()[2]\n",
        "        img_mask_sub_s = torch.ones(1,img_size_h,img_size_w).type(torch.FloatTensor)\n",
        "        img_mask_sub_s = img_mask_sub_s*255.0\n",
        "        img_mask_sub = torch.cat((ii,img_mask_sub_s),dim=0)\n",
        "        padding_h = aa1-img_size_h\n",
        "        padding_w = bb1-img_size_w\n",
        "        m = torch.nn.ZeroPad2d((0,padding_w,0,padding_h))\n",
        "        img_mask_sub_padding = m(img_mask_sub)\n",
        "        img_mask_sub_padding = img_mask_sub_padding.unsqueeze(0)\n",
        "        if k==0:\n",
        "            img_padding_mask = img_mask_sub_padding\n",
        "        else:\n",
        "            img_padding_mask = torch.cat((img_padding_mask,img_mask_sub_padding),dim=0)\n",
        "        k = k+1\n",
        "\n",
        "    for ii1 in label:\n",
        "        ii1 = ii1.long()\n",
        "        ii1 = ii1.unsqueeze(0)\n",
        "        ii1_len = ii1.size()[1]\n",
        "        m = torch.nn.ZeroPad2d((0,max_len-ii1_len,0,0))\n",
        "        ii1_padding = m(ii1)\n",
        "        if k1 == 0:\n",
        "            label_padding = ii1_padding\n",
        "        else:\n",
        "            label_padding = torch.cat((label_padding,ii1_padding),dim=0)\n",
        "        k1 = k1+1\n",
        "\n",
        "    img_padding_mask = img_padding_mask/255.0\n",
        "    return img_padding_mask, label_padding\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = off_image_train,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    # num_workers=2,\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset = off_image_test,\n",
        "    batch_size = batch_size_t,\n",
        "    shuffle = True,\n",
        "    collate_fn = collate_fn,\n",
        "    # num_workers=2,\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41v3UxF71z2K"
      },
      "source": [
        "def my_train(target_length,attn_decoder1,\n",
        "             output_highfeature, output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
        "             decoder_input,decoder_hidden,attention_sum,decoder_attention):\n",
        "    loss = 0\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    flag_z = [0]*batch_size\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        encoder_optimizer1.zero_grad()\n",
        "        decoder_optimizer1.zero_grad()\n",
        "        my_num = 0\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention, attention_sum = attn_decoder1(decoder_input,\n",
        "                                                                                             decoder_hidden,\n",
        "                                                                                             output_highfeature,\n",
        "                                                                                             output_area,\n",
        "                                                                                             attention_sum,\n",
        "                                                                                             decoder_attention,\n",
        "                                                                                             dense_input,batch_size,h_mask,w_mask,gpu)\n",
        "            \n",
        "            \n",
        "            #print(decoder_output.size()) (batch,1,112)\n",
        "            y = y.unsqueeze(0)\n",
        "            for i in range(batch_size):\n",
        "                if int(y[0][i][di]) == 0:\n",
        "                    flag_z[i] = flag_z[i]+1\n",
        "                    if flag_z[i] > 1:\n",
        "                        continue\n",
        "                    else:\n",
        "                        loss += criterion(decoder_output[i], y[:,i,di])\n",
        "                else:\n",
        "                    loss += criterion(decoder_output[i], y[:,i,di])\n",
        "\n",
        "            if int(y[0][0][di]) == 0:\n",
        "                break\n",
        "            decoder_input = y[:,:,di]\n",
        "            decoder_input = decoder_input.squeeze(0)\n",
        "            y = y.squeeze(0)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer1.step()\n",
        "        decoder_optimizer1.step()\n",
        "        return loss.item()\n",
        "\n",
        "    else:\n",
        "        encoder_optimizer1.zero_grad()\n",
        "        decoder_optimizer1.zero_grad()\n",
        "        my_num = 0\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention,attention_sum= attn_decoder1(decoder_input, decoder_hidden,\n",
        "                                                                                output_highfeature, output_area,\n",
        "                                                                                attention_sum,decoder_attention,dense_input,batch_size,\n",
        "                                                                                h_mask,w_mask,gpu)\n",
        "            #print(decoder_output.size()) 1*10*112\n",
        "            #print(y.size())  1*37\n",
        "            #topi (b,1)\n",
        "            topv,topi = torch.max(decoder_output,2)\n",
        "            decoder_input = topi\n",
        "            decoder_input = decoder_input.view(batch_size)\n",
        "\n",
        "            y = y.unsqueeze(0)\n",
        "            #print(y_t)\n",
        "\n",
        "            # 1*bs*17\n",
        "            for k in range(batch_size):\n",
        "                if int(y[0][k][di]) == 0:\n",
        "                    flag_z[k] = flag_z[k]+1\n",
        "                    if flag_z[k] > 1:\n",
        "                        continue\n",
        "                    else:\n",
        "                        loss += criterion(decoder_output[k], y[:,k,di])\n",
        "                else:\n",
        "                    loss += criterion(decoder_output[k], y[:,k,di])\n",
        "\n",
        "            y = y.squeeze(0)\n",
        "            # if int(topi[0]) == 0:\n",
        "            #     break\n",
        "        loss.backward()\n",
        "        encoder_optimizer1.step()\n",
        "        decoder_optimizer1.step()\n",
        "        return loss.item()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2k8uTbz313W"
      },
      "source": [
        "gpu = [torch.cuda.current_device()]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVuKzMZe1z2V"
      },
      "source": [
        "encoder = densenet121()\n",
        "\n",
        "pthfile = f'{PATH}densenet121-a639ec97.pth'\n",
        "pretrained_dict = torch.load(pthfile) \n",
        "encoder_dict = encoder.state_dict()\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in encoder_dict}\n",
        "encoder_dict.update(pretrained_dict)\n",
        "encoder.load_state_dict(encoder_dict)\n",
        "\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size,112,dropout_p=0.5)\n",
        "\n",
        "encoder=encoder.cuda() #gpu\n",
        "attn_decoder1 = attn_decoder1.cuda()\n",
        "encoder = torch.nn.DataParallel(encoder, device_ids=gpu)\n",
        "attn_decoder1 = torch.nn.DataParallel(attn_decoder1, device_ids=gpu)\n",
        "\n",
        "# encoder = torch.nn.DataParallel(encoder)\n",
        "# attn_decoder1 = torch.nn.DataParallel(attn_decoder1)\n",
        "attn_decoder1.load_state_dict(torch.load(f'{PATH}model/attn_decoder_v1.pkl'))\n",
        "encoder.load_state_dict(torch.load(f'{PATH}model/encoder_v1.pkl'))\n",
        "\n",
        "def imresize(im,sz):\n",
        "    pil_im = Image.fromarray(im)\n",
        "    return numpy.array(pil_im.resize(sz))\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vrkb8nKbew80",
        "outputId": "771eaf88-f14f-4bc8-debb-1b504ea9f0e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# this is the prediction and compute wer loss\n",
        "total_dist = 0\n",
        "total_label = 0\n",
        "total_line = 0\n",
        "total_line_rec = 0\n",
        "whole_loss_t = 0\n",
        "\n",
        "encoder.eval()\n",
        "attn_decoder1.eval()\n",
        "print('Now, begin testing!!')\n",
        "\n",
        "#     for step_t, (x_t, y_t) in tqdm(enumerate(test_loader)):\n",
        "for step_t, (x_t, y_t) in enumerate(test_loader):\n",
        "  x_real_high = x_t.size()[2]\n",
        "  x_real_width = x_t.size()[3]\n",
        "  if x_t.size()[0]<batch_size_t:\n",
        "      break\n",
        "  print('testing for %.3f%%'%(step_t*100*batch_size_t/len_test),end='\\r')\n",
        "  h_mask_t = []\n",
        "  w_mask_t = []\n",
        "  for i in x_t:\n",
        "      #h*w\n",
        "      size_mask_t = i[1].size()\n",
        "      s_w_t = str(i[1][0])\n",
        "      s_h_t = str(i[1][:,1])\n",
        "      w_t = s_w_t.count('1')\n",
        "      h_t = s_h_t.count('1')\n",
        "      h_comp_t = int(h_t/16)+1\n",
        "      w_comp_t = int(w_t/16)+1\n",
        "      h_mask_t.append(h_comp_t)\n",
        "      w_mask_t.append(w_comp_t)\n",
        "\n",
        "  x_t = x_t.cuda()\n",
        "  y_t = y_t.cuda()\n",
        "  output_highfeature_t = encoder(x_t)\n",
        "\n",
        "  x_mean_t = torch.mean(output_highfeature_t)\n",
        "  x_mean_t = float(x_mean_t)\n",
        "  output_area_t1 = output_highfeature_t.size()\n",
        "  output_area_t = output_area_t1[3]\n",
        "  dense_input = output_area_t1[2]\n",
        "\n",
        "  decoder_input_t = torch.LongTensor([111]*batch_size_t)\n",
        "  decoder_input_t = decoder_input_t.cuda()\n",
        "  decoder_hidden_t = torch.randn(batch_size_t, 1, hidden_size).cuda()\n",
        "  nn.init.xavier_uniform_(decoder_hidden_t)\n",
        "\n",
        "  x_mean_t=[]\n",
        "  for i in output_highfeature_t:\n",
        "      x_mean_t.append(float(torch.mean(i)))\n",
        "  # x_mean = torch.mean(output_highfeature)\n",
        "  # x_mean = float(x_mean)\n",
        "  for i in range(batch_size_t):\n",
        "      decoder_hidden_t[i] = decoder_hidden_t[i]*x_mean_t[i]\n",
        "      decoder_hidden_t[i] = torch.tanh(decoder_hidden_t[i])\n",
        "\n",
        "  prediction = torch.zeros(batch_size_t,maxlen)\n",
        "  #label = torch.zeros(batch_size_t,maxlen)\n",
        "  prediction_sub = []\n",
        "  label_sub = []\n",
        "  decoder_attention_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "  attention_sum_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "  flag_z_t = [0]*batch_size_t\n",
        "  loss_t = 0\n",
        "  m = torch.nn.ZeroPad2d((0,maxlen-y_t.size()[1],0,0))\n",
        "  y_t = m(y_t)\n",
        "  for i in range(maxlen):\n",
        "      decoder_output, decoder_hidden_t, decoder_attention_t, attention_sum_t = attn_decoder1(decoder_input_t,\n",
        "                                                                                        decoder_hidden_t,\n",
        "                                                                                        output_highfeature_t,\n",
        "                                                                                        output_area_t,\n",
        "                                                                                        attention_sum_t,\n",
        "                                                                                        decoder_attention_t,dense_input,batch_size_t,h_mask_t,w_mask_t,gpu)\n",
        "\n",
        "      ### you can see the attention when testing\n",
        "\n",
        "      # print('this is',i)\n",
        "      # for i in range(batch_size_t):\n",
        "      #     x_real = numpy.array(x_t[i][0].data.cpu())\n",
        "\n",
        "      #     show = numpy.array(decoder_attention_t[i][0].data.cpu())\n",
        "      #     show = imresize(show,(x_real_width,x_real_high))\n",
        "      #     k_max = show.max()\n",
        "      #     show = show/k_max\n",
        "\n",
        "      #     show_x = x_real+show\n",
        "      #     plt.imshow(show_x, interpolation='nearest', cmap='gray_r')\n",
        "      #     plt.show()\n",
        "      \n",
        "      topv,topi = torch.max(decoder_output,2)\n",
        "      # if torch.sum(y_t[0,:,i])==0:\n",
        "      #     y_t = y_t.squeeze(0)\n",
        "      #     break\n",
        "      if torch.sum(topi)==0:\n",
        "          break\n",
        "      decoder_input_t = topi\n",
        "      decoder_input_t = decoder_input_t.view(batch_size_t)\n",
        "\n",
        "      # prediction\n",
        "      prediction[:,i] = decoder_input_t\n",
        "\n",
        "  for i in range(batch_size_t):\n",
        "      for j in range(maxlen):\n",
        "          if int(prediction[i][j]) ==0:\n",
        "              break\n",
        "          else:\n",
        "              prediction_sub.append(int(prediction[i][j]))\n",
        "      if len(prediction_sub)<maxlen:\n",
        "          prediction_sub.append(0)\n",
        "\n",
        "      for k in range(y_t.size()[1]):\n",
        "          if int(y_t[i][k]) ==0:\n",
        "              break\n",
        "          else:\n",
        "              label_sub.append(int(y_t[i][k]))\n",
        "      label_sub.append(0)\n",
        "\n",
        "      dist, llen = cmp_result(label_sub, prediction_sub)\n",
        "      total_dist += dist\n",
        "      total_label += llen\n",
        "      total_line += 1\n",
        "      if dist == 0:\n",
        "          total_line_rec = total_line_rec+ 1\n",
        "\n",
        "      label_sub = []\n",
        "      prediction_sub = []\n",
        "\n",
        "print('total_line_rec is',total_line_rec)\n",
        "wer = float(total_dist) / total_label\n",
        "sacc = float(total_line_rec) / total_line\n",
        "print('wer is %.5f' % (wer))\n",
        "print('sacc is %.5f ' % (sacc))\n",
        "# print('whole loss is %.5f'%(whole_loss_t/925))\n",
        "# with open(\"training_data/wer_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "#     f.write(\"%s\\n\" % (str(wer)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now, begin testing!!\n",
            "total_line_rec is 367\n",
            "wer is 0.16819\n",
            "sacc is 0.39719 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEVf1EdMmIJC",
        "outputId": "8f321d2a-a259-4df9-9fb4-c7ef9a6d0d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lr_rate"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ4hWX0x1z2c",
        "outputId": "b76050d7-9c1e-41cc-a0a7-454fa34ff531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "criterion = nn.NLLLoss()\n",
        "\n",
        "decoder_input_init = torch.LongTensor([111]*batch_size).cuda() #gpu\n",
        "decoder_hidden_init = torch.randn(batch_size, 1, hidden_size).cuda()\n",
        "# decoder_input_init = torch.LongTensor([111]*batch_size)\n",
        "# decoder_hidden_init = torch.randn(batch_size, 1, hidden_size)\n",
        "nn.init.xavier_uniform_(decoder_hidden_init)\n",
        "\n",
        "encoder_optimizer1 = torch.optim.Adam(encoder.parameters(), lr=lr_rate)\n",
        "decoder_optimizer1 = torch.optim.Adam(attn_decoder1.parameters(), lr=lr_rate)\n",
        "\n",
        "for epoch in tqdm(range(5)):\n",
        "#     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "#     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "\n",
        "    # # if using SGD optimizer\n",
        "    # if epoch+1 == 50:\n",
        "    #     lr_rate = lr_rate/10\n",
        "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    # if epoch+1 == 75:\n",
        "    #     lr_rate = lr_rate/10\n",
        "    #     encoder_optimizer1 = torch.optim.SGD(encoder.parameters(), lr=lr_rate,momentum=0.9)\n",
        "    #     decoder_optimizer1 = torch.optim.SGD(attn_decoder1.parameters(), lr=lr_rate,momentum=0.9)\n",
        "\n",
        "\n",
        "    running_loss=0\n",
        "    whole_loss = 0\n",
        "\n",
        "    encoder.train(mode=True)\n",
        "    attn_decoder1.train(mode=True)\n",
        "\n",
        "    # this is the train\n",
        "#     for step,(x,y) in tqdm(enumerate(train_loader)):\n",
        "    for step,(x,y) in enumerate(train_loader):\n",
        "        if x.size()[0]<batch_size:\n",
        "            break\n",
        "        h_mask = []\n",
        "        w_mask = []\n",
        "        for i in x:\n",
        "            #h*w\n",
        "            size_mask = i[1].size()\n",
        "            s_w = str(i[1][0])\n",
        "            s_h = str(i[1][:,1])\n",
        "            w = s_w.count('1')\n",
        "            h = s_h.count('1')\n",
        "            h_comp = int(h/16)+1\n",
        "            w_comp = int(w/16)+1\n",
        "            h_mask.append(h_comp)\n",
        "            w_mask.append(w_comp)\n",
        "\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "        # out is CNN featuremaps\n",
        "        output_highfeature = encoder(x)\n",
        "        x_mean=[]\n",
        "        for i in output_highfeature:\n",
        "            x_mean.append(float(torch.mean(i)))\n",
        "        # x_mean = torch.mean(output_highfeature)\n",
        "        # x_mean = float(x_mean)\n",
        "        for i in range(batch_size):\n",
        "            decoder_hidden_init[i] = decoder_hidden_init[i]*x_mean[i]\n",
        "            decoder_hidden_init[i] = torch.tanh(decoder_hidden_init[i])\n",
        "\n",
        "        # dense_input is height and output_area is width which is bb\n",
        "        output_area1 = output_highfeature.size()\n",
        "\n",
        "        output_area = output_area1[3]\n",
        "        dense_input = output_area1[2]\n",
        "        target_length = y.size()[1]\n",
        "        attention_sum_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
        "        decoder_attention_init = torch.zeros(batch_size,1,dense_input,output_area).cuda()\n",
        "\n",
        "        running_loss += my_train(target_length,attn_decoder1,output_highfeature,\n",
        "                                output_area,y,criterion,encoder_optimizer1,decoder_optimizer1,x_mean,dense_input,h_mask,w_mask,gpu,\n",
        "                                decoder_input_init,decoder_hidden_init,attention_sum_init,decoder_attention_init)\n",
        "\n",
        "        \n",
        "        if step % 20 == 19:\n",
        "            pre = ((step+1)/len_train)*100*batch_size\n",
        "            whole_loss += running_loss\n",
        "            running_loss = running_loss/(batch_size*20)\n",
        "            print('epoch is %d, lr rate is %.5f, te is %.3f, batch_size is %d, loading for %.3f%%, running_loss is %f' %(epoch,lr_rate,teacher_forcing_ratio, batch_size,pre,running_loss))\n",
        "            # with open(\"training_data/running_loss_%.5f_pre_GN_te05_d02_all.txt\" %(lr_rate),\"a\") as f:\n",
        "            #     f.write(\"%s\\n\"%(str(running_loss)))\n",
        "            running_loss = 0\n",
        "\n",
        "    loss_all_out = whole_loss / len_train\n",
        "    print(\"epoch is %d, the whole loss is %f\" % (epoch, loss_all_out))\n",
        "    # with open(\"training_data/whole_loss_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "    #     f.write(\"%s\\n\" % (str(loss_all_out)))\n",
        "\n",
        "    # this is the prediction and compute wer loss\n",
        "    total_dist = 0\n",
        "    total_label = 0\n",
        "    total_line = 0\n",
        "    total_line_rec = 0\n",
        "    whole_loss_t = 0\n",
        "\n",
        "    encoder.eval()\n",
        "    attn_decoder1.eval()\n",
        "    print('Now, begin testing!!')\n",
        "\n",
        "#     for step_t, (x_t, y_t) in tqdm(enumerate(test_loader)):\n",
        "    for step_t, (x_t, y_t) in enumerate(test_loader):\n",
        "        x_real_high = x_t.size()[2]\n",
        "        x_real_width = x_t.size()[3]\n",
        "        if x_t.size()[0]<batch_size_t:\n",
        "            break\n",
        "        print('testing for %.3f%%'%(step_t*100*batch_size_t/len_test),end='\\r')\n",
        "        h_mask_t = []\n",
        "        w_mask_t = []\n",
        "        for i in x_t:\n",
        "            #h*w\n",
        "            size_mask_t = i[1].size()\n",
        "            s_w_t = str(i[1][0])\n",
        "            s_h_t = str(i[1][:,1])\n",
        "            w_t = s_w_t.count('1')\n",
        "            h_t = s_h_t.count('1')\n",
        "            h_comp_t = int(h_t/16)+1\n",
        "            w_comp_t = int(w_t/16)+1\n",
        "            h_mask_t.append(h_comp_t)\n",
        "            w_mask_t.append(w_comp_t)\n",
        "\n",
        "        x_t = x_t.cuda()\n",
        "        y_t = y_t.cuda()\n",
        "        output_highfeature_t = encoder(x_t)\n",
        "\n",
        "        x_mean_t = torch.mean(output_highfeature_t)\n",
        "        x_mean_t = float(x_mean_t)\n",
        "        output_area_t1 = output_highfeature_t.size()\n",
        "        output_area_t = output_area_t1[3]\n",
        "        dense_input = output_area_t1[2]\n",
        "\n",
        "        decoder_input_t = torch.LongTensor([111]*batch_size_t)\n",
        "        decoder_input_t = decoder_input_t.cuda()\n",
        "        decoder_hidden_t = torch.randn(batch_size_t, 1, hidden_size).cuda()\n",
        "        nn.init.xavier_uniform_(decoder_hidden_t)\n",
        "\n",
        "        x_mean_t=[]\n",
        "        for i in output_highfeature_t:\n",
        "            x_mean_t.append(float(torch.mean(i)))\n",
        "        # x_mean = torch.mean(output_highfeature)\n",
        "        # x_mean = float(x_mean)\n",
        "        for i in range(batch_size_t):\n",
        "            decoder_hidden_t[i] = decoder_hidden_t[i]*x_mean_t[i]\n",
        "            decoder_hidden_t[i] = torch.tanh(decoder_hidden_t[i])\n",
        "\n",
        "        prediction = torch.zeros(batch_size_t,maxlen)\n",
        "        #label = torch.zeros(batch_size_t,maxlen)\n",
        "        prediction_sub = []\n",
        "        label_sub = []\n",
        "        decoder_attention_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "        attention_sum_t = torch.zeros(batch_size_t,1,dense_input,output_area_t).cuda()\n",
        "        flag_z_t = [0]*batch_size_t\n",
        "        loss_t = 0\n",
        "        m = torch.nn.ZeroPad2d((0,maxlen-y_t.size()[1],0,0))\n",
        "        y_t = m(y_t)\n",
        "        for i in range(maxlen):\n",
        "            decoder_output, decoder_hidden_t, decoder_attention_t, attention_sum_t = attn_decoder1(decoder_input_t,\n",
        "                                                                                             decoder_hidden_t,\n",
        "                                                                                             output_highfeature_t,\n",
        "                                                                                             output_area_t,\n",
        "                                                                                             attention_sum_t,\n",
        "                                                                                             decoder_attention_t,dense_input,batch_size_t,h_mask_t,w_mask_t,gpu)\n",
        "\n",
        "            ### you can see the attention when testing\n",
        "\n",
        "            # print('this is',i)\n",
        "            # for i in range(batch_size_t):\n",
        "            #     x_real = numpy.array(x_t[i][0].data.cpu())\n",
        "\n",
        "            #     show = numpy.array(decoder_attention_t[i][0].data.cpu())\n",
        "            #     show = imresize(show,(x_real_width,x_real_high))\n",
        "            #     k_max = show.max()\n",
        "            #     show = show/k_max\n",
        "\n",
        "            #     show_x = x_real+show\n",
        "            #     plt.imshow(show_x, interpolation='nearest', cmap='gray_r')\n",
        "            #     plt.show()\n",
        "            \n",
        "            topv,topi = torch.max(decoder_output,2)\n",
        "            # if torch.sum(y_t[0,:,i])==0:\n",
        "            #     y_t = y_t.squeeze(0)\n",
        "            #     break\n",
        "            if torch.sum(topi)==0:\n",
        "                break\n",
        "            decoder_input_t = topi\n",
        "            decoder_input_t = decoder_input_t.view(batch_size_t)\n",
        "\n",
        "            # prediction\n",
        "            prediction[:,i] = decoder_input_t\n",
        "\n",
        "        for i in range(batch_size_t):\n",
        "            for j in range(maxlen):\n",
        "                if int(prediction[i][j]) ==0:\n",
        "                    break\n",
        "                else:\n",
        "                    prediction_sub.append(int(prediction[i][j]))\n",
        "            if len(prediction_sub)<maxlen:\n",
        "                prediction_sub.append(0)\n",
        "\n",
        "            for k in range(y_t.size()[1]):\n",
        "                if int(y_t[i][k]) ==0:\n",
        "                    break\n",
        "                else:\n",
        "                    label_sub.append(int(y_t[i][k]))\n",
        "            label_sub.append(0)\n",
        "\n",
        "            dist, llen = cmp_result(label_sub, prediction_sub)\n",
        "            total_dist += dist\n",
        "            total_label += llen\n",
        "            total_line += 1\n",
        "            if dist == 0:\n",
        "                total_line_rec = total_line_rec+ 1\n",
        "\n",
        "            label_sub = []\n",
        "            prediction_sub = []\n",
        "\n",
        "    print('total_line_rec is',total_line_rec)\n",
        "    wer = float(total_dist) / total_label\n",
        "    sacc = float(total_line_rec) / total_line\n",
        "    print('wer is %.5f' % (wer))\n",
        "    print('sacc is %.5f ' % (sacc))\n",
        "    # print('whole loss is %.5f'%(whole_loss_t/925))\n",
        "    # with open(\"training_data/wer_%.5f_pre_GN_te05_d02_all.txt\" % (lr_rate), \"a\") as f:\n",
        "    #     f.write(\"%s\\n\" % (str(wer)))\n",
        "\n",
        "    if (sacc > exprate):\n",
        "        exprate = sacc\n",
        "        print(exprate)\n",
        "        print(\"saving the model....\")\n",
        "        print('encoder_lr%.5f_GN_te1_d05_SGD_bs6_mask_conv_bn_b_xavier.pkl' %(lr_rate))\n",
        "        torch.save(encoder.state_dict(), f'{PATH}model/encoder_v2.pkl')\n",
        "        torch.save(attn_decoder1.state_dict(), f'{PATH}model/attn_decoder_v2.pkl')\n",
        "        print(\"done\")\n",
        "        flag = 0\n",
        "    else:\n",
        "        flag = flag+1\n",
        "        print('the best is %f' % (exprate))\n",
        "        print('the loss is bigger than before,so do not save the model')\n",
        "\n",
        "    if flag == 10:\n",
        "        lr_rate = lr_rate*0.1\n",
        "        flag = 0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch is 0, lr rate is 0.00100, te is 1.000, batch_size is 6, loading for 1.436%, running_loss is 9.024268\n",
            "epoch is 0, lr rate is 0.00100, te is 1.000, batch_size is 6, loading for 2.871%, running_loss is 7.834287\n",
            "epoch is 0, lr rate is 0.00100, te is 1.000, batch_size is 6, loading for 4.307%, running_loss is 10.634634\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9ea9d10637c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m         running_loss += my_train(target_length,attn_decoder1,output_highfeature,\n\u001b[1;32m     75\u001b[0m                                 \u001b[0moutput_area\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_optimizer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_optimizer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdense_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                                 decoder_input_init,decoder_hidden_init,attention_sum_init,decoder_attention_init)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-7977fe9364a5>\u001b[0m in \u001b[0;36mmy_train\u001b[0;34m(target_length, attn_decoder1, output_highfeature, output_area, y, criterion, encoder_optimizer1, decoder_optimizer1, x_mean, dense_input, h_mask, w_mask, gpu, decoder_input, decoder_hidden, attention_sum, decoder_attention)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                                                                              \u001b[0mattention_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                                                              \u001b[0mdecoder_attention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                                                                              dense_input,batch_size,h_mask,w_mask,gpu)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/Math_to_latex/Attention_RNN.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_a, hidden, encoder_outputs, bb, attention_sum, decoder_attention, dense_input, batch_size, h_mask, w_mask, gpu)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# et_div_all is attention alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0met_div_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdense_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0met_div_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0met_div_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0met_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIip6qBynGqX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}